<!--Copyright Â© ZOMI é€‚ç”¨äº[License](https://github.com/Infrasys-AI/AIInfra)ç‰ˆæƒè®¸å¯-->

# CODE 03: Pipeline å¹¶è¡Œå®è·µ

Author by: è®¸ç¿å²·

æœ¬å®éªŒæ—¨åœ¨æ·±å…¥ç†è§£ Pipeline å¹¶è¡ŒåŸç†ã€‚å…ˆå®ç° Gpipe æµæ°´çº¿å¹¶åˆ†æç©ºæ³¡ç‡ç°è±¡ï¼Œåè¿›é˜¶å®ç° 1F1B å’Œ Interleaved 1F1B è°ƒåº¦ç­–ç•¥ï¼Œä¼˜åŒ–ç©ºæ³¡ç‡ç°è±¡ï¼Œå¹¶å®è·µæ··åˆå¹¶è¡Œç­–ç•¥ã€‚

## 1. Pipeline å¹¶è¡ŒåŸºç¡€

**Pipeline å¹¶è¡Œï¼ˆPipeline Parallelism, PPï¼‰** å…¶æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸€ä¸ªåºå¤§çš„ç¥ç»ç½‘ç»œæ¨¡å‹ï¼Œæ²¿ç€å±‚ï¼ˆLayerï¼‰çš„ç»´åº¦è¿›è¡Œçºµå‘åˆ‡å‰²ï¼Œåˆ†å‰²æˆå¤šä¸ªè¿ç»­çš„å­æ¨¡å—ï¼ˆç§°ä¸ºâ€œé˜¶æ®µâ€ï¼ŒStageï¼‰ï¼Œå¹¶å°†è¿™äº›é˜¶æ®µéƒ¨ç½²åˆ°ä¸åŒçš„è®¡ç®—è®¾å¤‡ï¼ˆå¦‚ GPUï¼‰ä¸Šã€‚

æ•°å­¦ä¸Šï¼Œæ¨¡å‹å¯è¡¨ç¤ºä¸ºå‡½æ•°å¤åˆï¼š$F(x) = f_n(f_{n-1}(...f_1(x)...))$ï¼Œå…¶ä¸­æ¯ä¸ª $f_i$ï¼ˆæ¨¡å‹å±‚/å±‚ç»„ï¼‰å¯¹åº” Pipeline çš„ä¸€ä¸ªâ€œé˜¶æ®µâ€ï¼Œåˆ†é…åˆ°ä¸åŒè®¾å¤‡ä¸Šæ‰§è¡Œã€‚æ•°æ®ä»¥â€œæ‰¹æ¬¡â€ï¼ˆbatchï¼‰çš„å½¢å¼ï¼Œåƒå·¥å‚æµæ°´çº¿ä¸€æ ·ï¼Œä¾æ¬¡æµç»å„ä¸ªé˜¶æ®µã€‚

é€šè¿‡è¿™ç§æ–¹å¼ï¼Œæ¯ä¸ªè®¾å¤‡åªéœ€åŠ è½½å’Œå¤„ç†æ¨¡å‹çš„ä¸€éƒ¨åˆ†ï¼Œä»è€Œçªç ´**å•å¡æ˜¾å­˜çš„é™åˆ¶**ã€‚

ç„¶è€Œï¼Œè¿™ç§æ‹†åˆ†ä¹Ÿå¼•å…¥äº†æ–°çš„æŒ‘æˆ˜ï¼š
*   **é€šä¿¡å¼€é”€ï¼š** å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œç›¸é‚»é˜¶æ®µä¹‹é—´éœ€è¦é¢‘ç¹åœ°ä¼ é€’ä¸­é—´ç»“æœï¼ˆæ¿€æ´»å€¼å’Œæ¢¯åº¦ï¼‰ï¼Œè¿™ä¼šå¸¦æ¥é¢å¤–çš„é€šä¿¡å»¶è¿Ÿã€‚
*   **ç©ºæ³¡ç°è±¡ï¼ˆBubbleï¼‰ï¼š** ç”±äºæµæ°´çº¿çš„â€œå¡«å……â€ï¼ˆFillï¼‰å’Œâ€œæ’ç©ºâ€ï¼ˆDrainï¼‰è¿‡ç¨‹ï¼Œéƒ¨åˆ†è®¾å¤‡åœ¨æŸäº›æ—¶åˆ»ä¼šå¤„äºç­‰å¾…æ•°æ®çš„ç©ºé—²çŠ¶æ€ï¼Œé€ æˆè®¡ç®—èµ„æºçš„æµªè´¹ã€‚

**åç»­ä¼˜åŒ–æ–¹å‘**ï¼š
Gpipeã€1F1Bã€Interleaved 1F1B ç­‰è°ƒåº¦ç­–ç•¥ï¼Œæœ¬è´¨éƒ½æ˜¯é€šè¿‡è°ƒæ•´ã€Œå‰å‘ã€å’Œã€Œåå‘ã€çš„æ‰§è¡ŒèŠ‚å¥ï¼Œæ¥**å‹ç¼©ç©ºæ³¡æ—¶é—´ã€é™ä½é€šä¿¡å½±å“ã€æ›´é«˜æ•ˆåˆ©ç”¨æ˜¾å­˜** â€”â€” è¿™äº›æˆ‘ä»¬å°†åœ¨ä»£ç å®è·µä¸­é€ä¸€å®ç°å’Œå¯¹æ¯”ã€‚

## 2. Native Pipeline Parallelismï¼ˆä¼ ç»Ÿæµæ°´çº¿å¹¶è¡Œï¼‰

é¦–å…ˆï¼Œæˆ‘ä»¬å®ç°ä¸€ä¸ªåŸºç¡€çš„æµæ°´çº¿å¹¶è¡Œæ¡†æ¶ï¼Œåªè€ƒè™‘äº†æ¨¡å‹åˆ†å‰²å’Œæµæ°´çº¿è°ƒåº¦ï¼Œå°†æ•°æ®ä»¥ batch ä¸ºå•ä½è¿›è¡Œå¤„ç†ã€‚

![](./images/Code03Pipeline01.png)
```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.nn.parameter import Parameter

def get_available_devices(max_devices=4):
    """è‡ªåŠ¨è·å–å¯ç”¨è®¾å¤‡ï¼Œè§£å†³åŸä»£ç è®¾å¤‡ç¡¬ç¼–ç é—®é¢˜"""
    devices = []
    num_cuda = torch.cuda.device_count()
    devices = [torch.device(f"cuda:{i}") for i in range(min(num_cuda, max_devices))]
    print(f"å½“å‰ä½¿ç”¨è®¾å¤‡åˆ—è¡¨: {[str(dev) for dev in devices]}")
    return devices

class PipelineParallel(nn.Module):
    def __init__(self, module_list, device_ids):
        super().__init__()
        assert len(module_list) == len(device_ids), "æ¨¡å—æ•°é‡å¿…é¡»ä¸è®¾å¤‡æ•°é‡ç›¸åŒ"

        self.stages = nn.ModuleList(module_list)
        self.device_ids = device_ids

        # å°†æ¯ä¸ªé˜¶æ®µç§»åŠ¨åˆ°å¯¹åº”çš„è®¾å¤‡
        for i, (stage, dev) in enumerate(zip(self.stages, device_ids)):
            self.stages[i] = stage.to(dev)

    def forward(self, x):
        """
        ç®€å•çš„å‰å‘ä¼ æ’­ Pipeline
        è¾“å…¥æ•°æ®ä¾æ¬¡é€šè¿‡æ¯ä¸ªé˜¶æ®µï¼Œä¿ç•™ä¸­é—´ç»“æœç”¨äºåå‘ä¼ æ’­
        """
        intermediates = []
        current_output = x.to(self.device_ids[0])  # è¾“å…¥å…ˆè¿ç§»åˆ°ç¬¬ä¸€é˜¶æ®µè®¾å¤‡

        # æ•°æ®ä¾æ¬¡é€šè¿‡æ¯ä¸ªé˜¶æ®µ
        for i, (stage, dev) in enumerate(zip(self.stages, self.device_ids)):
            current_output = stage(current_output)  # æœ¬é˜¶æ®µè®¡ç®—
            if i < len(self.stages) - 1:
                # ä¿ç•™ä¸­é—´ç»“æœï¼ˆdetach é¿å…æ¢¯åº¦æå‰è®¡ç®—ï¼‰
                intermediates.append(current_output.detach().clone())
                # ä¼ é€’åˆ°ä¸‹ä¸€é˜¶æ®µè®¾å¤‡
                current_output = current_output.to(self.device_ids[i+1])

        return current_output, intermediates
```

ä¸Šé¢çš„ä»£ç å®ç°äº†ä¸€ä¸ªåŸºç¡€çš„æµæ°´çº¿å¹¶è¡Œæ¡†æ¶ã€‚å®ƒå°†æ¨¡å‹åˆ†å‰²ä¸ºå¤šä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µæ”¾ç½®åœ¨ä¸åŒçš„è®¾å¤‡ä¸Šã€‚åœ¨å‰å‘ä¼ æ’­è¿‡ç¨‹ä¸­ï¼Œæ•°æ®ä¾æ¬¡é€šè¿‡è¿™äº›é˜¶æ®µï¼Œå¹¶åœ¨é˜¶æ®µé—´è¿›è¡Œè®¾å¤‡é—´çš„æ•°æ®ä¼ è¾“ã€‚

## 3. Gpipe æµæ°´çº¿å¹¶è¡Œ

Gpipe(Gradient Pipeline) æ˜¯ä¸€ç§åŸºäºæµæ°´çº¿å¹¶è¡Œçš„æ¨¡å‹å¹¶è¡Œç­–ç•¥ï¼Œå®ƒå°†ä¸€ä¸ªå¤§çš„è®­ç»ƒæ‰¹æ¬¡ï¼ˆBatchï¼‰æ‹†åˆ†æˆå¤šä¸ªå°çš„å¾®æ‰¹æ¬¡ï¼ˆMicro-batchï¼‰ï¼Œä¾æ¬¡æµè¿‡ Pipeline çš„å„ä¸ªé˜¶æ®µï¼Œæ¯ä¸ªé˜¶æ®µæ”¾ç½®åœ¨ä¸åŒçš„è®¾å¤‡ä¸Šã€‚

![](./images/Code03Pipeline02.png)

## 4. ç©ºæ³¡ç‡åˆ†æä¸è®¡ç®—

**ç©ºæ³¡ç‡**æ˜¯è¡¡é‡æµæ°´çº¿å¹¶è¡Œæ•ˆç‡çš„é‡è¦æŒ‡æ ‡ï¼Œè¡¨ç¤ºç”±äºæµæ°´çº¿å¡«å……å’Œæ’ç©ºé€ æˆçš„è®¡ç®—èµ„æºæµªè´¹æ¯”ä¾‹ã€‚ç©ºæ³¡ç‡çš„è®¡ç®—åŸºäºæµæ°´çº¿å¡«å……å’Œæ’ç©ºçš„æ—¶é—´å¼€é”€ã€‚å½“å¾®æ‰¹æ¬¡æ•°é‡è¿œå¤§äºæµæ°´çº¿é˜¶æ®µæ•°æ—¶ï¼Œç©ºæ³¡ç‡ä¼šé™ä½ï¼Œå› ä¸ºå¡«å……å’Œæ’ç©ºæ—¶é—´ç›¸å¯¹äºæ€»è®¡ç®—æ—¶é—´çš„æ¯”ä¾‹å˜å°ã€‚

æˆ‘ä»¬åœ¨è¿™é‡Œä»¥**Gpipe æµæ°´çº¿å¹¶è¡Œ**çš„ç©ºæ³¡ç‡è®¡ç®—ä¸ºä¾‹ï¼Œè®¡ç®—ç©ºæ³¡ç‡ã€‚

åœ¨æ•°å­¦ä¸Šï¼Œç©ºæ³¡ç‡å¯ä»¥è¡¨ç¤ºä¸ºï¼š

$$
Bubble = (T_{fill} + T_{drain}) / (T_{total}) = (S - 1 + S - 1) / (2*(M + S - 1)) = (S - 1) / (M + S - 1)
$$

å…¶ä¸­ $S$ æ˜¯æµæ°´çº¿é˜¶æ®µæ•°ï¼Œ$M$ æ˜¯å¾®æ‰¹æ¬¡æ•°é‡ã€‚$T_{fill}$ è¡¨ç¤ºæµæ°´çº¿å¡«å……æ—¶é—´ï¼Œ$T_{drain}$ è¡¨ç¤ºæµæ°´çº¿æ’ç©ºæ—¶é—´,$T_{total}$ è¡¨ç¤ºæµæ°´çº¿æ€»æ—¶é—´ã€‚


```python
def calculate_bubble_rate(num_stages, num_microbatches):
    """
    è®¡ç®— Pipeline å¹¶è¡Œçš„ç©ºæ³¡ç‡

    å‚æ•°:
        num_stages: Pipeline é˜¶æ®µæ•°ï¼ˆSï¼‰
        num_microbatches: å¾®æ‰¹æ¬¡æ•°é‡ï¼ˆMï¼‰

    è¿”å›:
        ç©ºæ³¡ç‡ï¼ˆ0~1 ä¹‹é—´ï¼Œå€¼è¶Šå°æ•ˆç‡è¶Šé«˜ï¼‰

    æ•°å­¦å…¬å¼:
        ç©ºæ³¡ç‡ = Pipeline å¡«å……æ—¶é—´ / æ€»æ—¶é—´ = (S - 1) / (M + S - 1)
        è¯´æ˜ï¼š1F1B ä¸­â€œæ’ç©ºé˜¶æ®µâ€ä¸åç»­å¾®æ‰¹æ¬¡çš„å‰å‘é‡å ï¼Œæ— éœ€é¢å¤–è®¡ç®—æ’ç©ºæ—¶é—´
    """
    if num_microbatches <= 0 or num_stages <= 0:
        raise ValueError("é˜¶æ®µæ•°å’Œå¾®æ‰¹æ¬¡æ•°é‡å¿…é¡»ä¸ºæ­£æ•´æ•°")

    # ç†æƒ³æ—¶é—´ï¼šä»…è®¡ç®—æ‰€æœ‰å¾®æ‰¹æ¬¡çš„æ—¶é—´ï¼ˆæ— ç©ºæ³¡ï¼‰
    ideal_time = num_microbatches
    # å®é™…æ—¶é—´ï¼šå¡«å……æ—¶é—´ï¼ˆS-1ï¼‰ + è®¡ç®—æ—¶é—´ï¼ˆMï¼‰
    actual_time = num_microbatches + num_stages - 1
    # ç©ºæ³¡ç‡ = ç©ºæ³¡æ—¶é—´ / å®é™…æ€»æ—¶é—´
    bubble_rate = (actual_time - ideal_time) / actual_time

    return bubble_rate

configurations = [
    # ã€å¯¹æ¯”ç»„ 1ã€‘å›ºå®š S=4ï¼Œè§‚å¯Ÿ M å¢å¤§å¦‚ä½•é™ä½ç©ºæ³¡ç‡ï¼ˆå±•ç¤ºæ”¶ç›Šé€’å‡ï¼‰
    (4, 4),   # M = Sï¼Œç©ºæ³¡ç‡è¾ƒé«˜ï¼Œä¸´ç•Œç‚¹
    (4, 8),   # M = 2S
    (4, 16),  # M = 4Sï¼ˆæ¨èå·¥ç¨‹èµ·ç‚¹ï¼‰
    (4, 32),  # M = 8S
    (4, 64),  # M = 16S
    (4, 100),  # M = 25Sï¼Œæ¥è¿‘ç†æƒ³

    # ã€å¯¹æ¯”ç»„ 2ã€‘å›ºå®š M=2Sï¼Œè§‚å¯Ÿ S å¢å¤§æ—¶ç©ºæ³¡ç‡å¦‚ä½•ä¸Šå‡ï¼ˆå±•ç¤ºè§„æ¨¡ä»£ä»·ï¼‰
    (8, 16),  # M = 2S
    (16, 32), # M = 2S
    (32, 64), # M = 2Sï¼ˆå¦‚èµ„æºå…è®¸ï¼‰

    # ã€å¯¹æ¯”ç»„ 3ã€‘å›ºå®š M=4Sï¼Œè§‚å¯Ÿä¸åŒè§„æ¨¡ä¸‹çš„è¡¨ç°ï¼ˆæ¨èå·¥ç¨‹é…ç½®ï¼‰
    (8, 32),  # M = 4S
    (16, 64), # M = 4S
]

print("=== ä¸åŒé…ç½®ä¸‹çš„ç©ºæ³¡ç‡è®¡ç®—ç»“æœ ===")
for num_stages, num_microbatches in configurations:
    rate = calculate_bubble_rate(num_stages, num_microbatches)
    print(f"é˜¶æ®µæ•°: {num_stages:3d}, å¾®æ‰¹æ¬¡: {num_microbatches:3d}, ç©ºæ³¡ç‡: {rate:.3f}")
```

```
=== ä¸åŒé…ç½®ä¸‹çš„ç©ºæ³¡ç‡è®¡ç®—ç»“æœ ===
é˜¶æ®µæ•°:   4, å¾®æ‰¹æ¬¡:   4, ç©ºæ³¡ç‡: 0.429
é˜¶æ®µæ•°:   4, å¾®æ‰¹æ¬¡:   8, ç©ºæ³¡ç‡: 0.273
é˜¶æ®µæ•°:   4, å¾®æ‰¹æ¬¡:  16, ç©ºæ³¡ç‡: 0.158
é˜¶æ®µæ•°:   4, å¾®æ‰¹æ¬¡:  32, ç©ºæ³¡ç‡: 0.086
é˜¶æ®µæ•°:   4, å¾®æ‰¹æ¬¡:  64, ç©ºæ³¡ç‡: 0.045
é˜¶æ®µæ•°:   4, å¾®æ‰¹æ¬¡: 100, ç©ºæ³¡ç‡: 0.029
é˜¶æ®µæ•°:   8, å¾®æ‰¹æ¬¡:  16, ç©ºæ³¡ç‡: 0.304
é˜¶æ®µæ•°:  16, å¾®æ‰¹æ¬¡:  32, ç©ºæ³¡ç‡: 0.319
é˜¶æ®µæ•°:  32, å¾®æ‰¹æ¬¡:  64, ç©ºæ³¡ç‡: 0.326
é˜¶æ®µæ•°:   8, å¾®æ‰¹æ¬¡:  32, ç©ºæ³¡ç‡: 0.179
é˜¶æ®µæ•°:  16, å¾®æ‰¹æ¬¡:  64, ç©ºæ³¡ç‡: 0.190
```

ä»ä¸Šé¢ä»£ç çš„è¿è¡Œç»“æœæˆ‘ä»¬å¯ä»¥çœ‹å‡ºï¼š
- **å¾®æ‰¹æ¬¡çš„å½±å“**ï¼šå½“ $M \gg S$ æ—¶ï¼Œç©ºæ³¡ç‡è¶‹è¿‘äº 0ï¼ˆå¦‚ $S=4, M=100$ï¼Œç©ºæ³¡ç‡â‰ˆ0.029ï¼‰ï¼Œå› æ­¤å¢åŠ å¾®æ‰¹æ¬¡æ˜¯é™ä½ç©ºæ³¡ç‡çš„æ ¸å¿ƒæ‰‹æ®µã€‚
- **é˜¶æ®µæ•°çš„å½±å“**ï¼š$S$ è¶Šå¤§ï¼Œç©ºæ³¡ç‡è¶Šé«˜ï¼ˆç›¸åŒ $M$ ä¸‹ï¼Œ$S=16$ æ¯” $S=4$ ç©ºæ³¡ç‡é«˜çº¦ 20%ï¼‰ï¼Œå› æ­¤ Pipeline é˜¶æ®µæ•°éœ€ä¸å¾®æ‰¹æ¬¡æ•°é‡åŒ¹é…ï¼ˆå»ºè®® $M \geq 4S$ï¼‰ã€‚

## 5. 1F1B è°ƒåº¦ç­–ç•¥å®ç°

1F1B(One-Forward-One-Backward) è°ƒåº¦æ˜¯ä¸€ç§ä¼˜åŒ–çš„æµæ°´çº¿å¹¶è¡Œç­–ç•¥ï¼Œå®ƒé€šè¿‡äº¤æ›¿æ‰§è¡Œå‰å‘å’Œåå‘ä¼ æ’­æ¥å‡å°‘å†…å­˜ä½¿ç”¨å’Œç©ºæ³¡æ—¶é—´ã€‚

![](./images/Code03Pipeline03.png)

```python
class PipelineParallel1F1B(nn.Module):
    """
    1F1B è°ƒåº¦ç­–ç•¥çš„ Pipeline å¹¶è¡Œ
    æ ¸å¿ƒæ”¹è¿›ï¼šè¡¥å…¨â€œå‰å‘â†’åå‘äº¤æ›¿â€é€»è¾‘ï¼Œå‡å°‘å†…å­˜å ç”¨å¹¶é™ä½ç©ºæ³¡ç‡
    """
    def __init__(self, module_list, device_ids, num_microbatches):
        super().__init__()
        self.stages = nn.ModuleList(module_list)
        self.device_ids = device_ids
        self.num_microbatches = num_microbatches  # å¾®æ‰¹æ¬¡æ•°é‡
        self.num_stages = len(self.stages)  # Pipeline é˜¶æ®µæ•°

        # é˜¶æ®µè®¾å¤‡åˆ†é…
        for i, (stage, dev) in enumerate(zip(self.stages, device_ids)):
            self.stages[i] = stage.to(dev)

    def forward(self, x):
        """
        1F1B è°ƒåº¦æ ¸å¿ƒé€»è¾‘ï¼š
        1. åˆ’åˆ†å¾®æ‰¹æ¬¡ â†’ 2. å‰å‘ä¼ æ’­ S ä¸ªå¾®æ‰¹æ¬¡ï¼ˆå¡«å…… Pipelineï¼‰â†’ 3. äº¤æ›¿æ‰§è¡Œå‰å‘ä¸åå‘
        """
        # 1. å°†è¾“å…¥æ•°æ®åˆ’åˆ†ä¸ºå¤šä¸ªå¾®æ‰¹æ¬¡ï¼ˆæŒ‰æ‰¹é‡ç»´åº¦åˆ†å‰²ï¼‰
        micro_batches = torch.chunk(x, self.num_microbatches, dim=0)
        # å­˜å‚¨å„é˜¶æ®µå‰å‘ç»“æœï¼ˆç”¨äºåç»­åå‘ä¼ æ’­ï¼‰
        stage_outputs = [[] for _ in range(self.num_stages)]
        total_loss = 0.0  # ç´¯è®¡æŸå¤±ï¼Œç”¨äºåç»­å¹³å‡

        # 2. 1F1B è°ƒåº¦æ‰§è¡Œ
        for mb_idx, mb in enumerate(micro_batches):
            # å‰å‘ä¼ æ’­ï¼šå½“å‰å¾®æ‰¹æ¬¡é€šè¿‡æ‰€æœ‰ Pipeline é˜¶æ®µ
            current_mb = mb.to(self.device_ids[0])
            for stage_idx, (stage, dev) in enumerate(zip(self.stages, self.device_ids)):
                current_mb = stage(current_mb)
                stage_outputs[stage_idx].append(current_mb)  # ä¿å­˜å½“å‰é˜¶æ®µè¾“å‡º
                if stage_idx < self.num_stages - 1:
                    current_mb = current_mb.to(self.device_ids[stage_idx+1])

            # 3. äº¤æ›¿åå‘ï¼šå½“å¾®æ‰¹æ¬¡ç´¢å¼• â‰¥ é˜¶æ®µæ•°æ—¶ï¼Œå¯¹æœ€æ—©çš„å¾®æ‰¹æ¬¡æ‰§è¡Œåå‘
            if mb_idx >= self.num_stages - 1:
                # å¾…åå‘çš„å¾®æ‰¹æ¬¡ç´¢å¼•ï¼ˆæœ€æ—©å¡«å……çš„å¾®æ‰¹æ¬¡ï¼šmb_idx - (S-1)ï¼‰
                reverse_mb_idx = mb_idx - (self.num_stages - 1)
                # ä»æœ€åä¸€ä¸ªé˜¶æ®µè·å–è¾“å‡ºï¼Œè®¡ç®—æŸå¤±ï¼ˆæ¨¡æ‹Ÿåˆ†ç±»ä»»åŠ¡ï¼‰
                final_output = stage_outputs[-1][reverse_mb_idx]
                # ç”ŸæˆåŒ¹é…è®¾å¤‡çš„æ ‡ç­¾ï¼ˆé¿å…è®¾å¤‡ä¸åŒ¹é…æŠ¥é”™ï¼‰
                label = torch.randint(0, 10, (final_output.shape[0],), device=final_output.device)
                # è®¡ç®—æŸå¤±ï¼ˆè§¦å‘åå‘ä¼ æ’­çš„å‰æï¼‰
                loss = F.cross_entropy(final_output, label)
                total_loss += loss.item()
                # æ¨¡æ‹Ÿåå‘ä¼ æ’­æ—¥å¿—ï¼ˆå®é™…åœºæ™¯éœ€è°ƒç”¨ loss.backward()å¹¶åŒæ­¥æ¢¯åº¦ï¼‰
                print(f"[1F1B è°ƒåº¦] å¾®æ‰¹æ¬¡{reverse_mb_idx:2d}åå‘è®¡ç®— | æŸå¤±: {loss.item():.4f}")

        # 4. å¤„ç†å‰©ä½™æœªåå‘çš„å¾®æ‰¹æ¬¡ï¼ˆæœ€å S-1 ä¸ªå¾®æ‰¹æ¬¡ï¼ŒPipeline æ’ç©ºé˜¶æ®µï¼‰
        for reverse_mb_idx in range(mb_idx - (self.num_stages - 2), self.num_microbatches):
            if reverse_mb_idx >= self.num_microbatches:
                break
            final_output = stage_outputs[-1][reverse_mb_idx]
            label = torch.randint(0, 10, (final_output.shape[0],), device=final_output.device)
            loss = F.cross_entropy(final_output, label)
            total_loss += loss.item()
            print(f"[1F1B è°ƒåº¦] å¾®æ‰¹æ¬¡{reverse_mb_idx:2d}åå‘è®¡ç®— | æŸå¤±: {loss.item():.4f}")

        # è¿”å›æ‰€æœ‰å¾®æ‰¹æ¬¡çš„å¹³å‡æŸå¤±
        avg_loss = total_loss / self.num_microbatches if self.num_microbatches > 0 else 0.0
        return torch.tensor(avg_loss, requires_grad=True)
```

1F1B è°ƒåº¦çš„æ ¸å¿ƒæ€æƒ³æ˜¯åœ¨æµæ°´çº¿ä¸­äº¤æ›¿æ‰§è¡Œå‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­ï¼Œè€Œä¸æ˜¯å…ˆå®Œæˆæ‰€æœ‰å‰å‘ä¼ æ’­å†è¿›è¡Œåå‘ä¼ æ’­ã€‚è¿™ç§ç­–ç•¥æœ‰ä¸¤ä¸ªä¸»è¦ä¼˜åŠ¿ï¼š

1. **å‡å°‘å†…å­˜ä½¿ç”¨**ï¼šä¸éœ€è¦å­˜å‚¨æ‰€æœ‰å¾®æ‰¹æ¬¡çš„å‰å‘ä¼ æ’­ä¸­é—´ç»“æœ
2. **é™ä½ç©ºæ³¡ç‡**ï¼šé€šè¿‡æ›´æ—©å¼€å§‹åå‘ä¼ æ’­ï¼Œå‡å°‘è®¾å¤‡ç©ºé—²æ—¶é—´

## 6. Interleaved 1F1B è°ƒåº¦ç­–ç•¥å®ç°

Interleaved 1F1B è°ƒåº¦æ˜¯ä¸€ç§æ”¹è¿›çš„ 1F1B è°ƒåº¦ç­–ç•¥ï¼Œå®ƒé€šè¿‡äº¤æ›¿æ‰§è¡Œå‰å‘å’Œåå‘ä¼ æ’­ï¼Œå¹¶å¼•å…¥é¢å¤–çš„å¡«å……å’Œæ’ç©ºæ­¥éª¤æ¥å‡å°‘ç©ºæ³¡ç‡ã€‚

![](./images/Code03Pipeline04.png)

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from typing import List

class PipelineParallelInterleaved1F1B(nn.Module):
    """
    Interleaved 1F1B è°ƒåº¦ç­–ç•¥çš„ Pipeline å¹¶è¡Œï¼ˆä¿®æ­£ç‰ˆï¼‰
    æ ¸å¿ƒæ€æƒ³ï¼š
      - æ¯ä¸ªç‰©ç†è®¾å¤‡è¿è¡Œå¤šä¸ªâ€œè™šæ‹Ÿé˜¶æ®µâ€ï¼Œäº¤é”™å¤„ç†ä¸åŒå¾®æ‰¹æ¬¡
      - å‰å‘å’Œåå‘ç´§å¯†äº¤é”™ï¼Œå‹ç¼©æµæ°´çº¿æ°”æ³¡
      - å¾®æ‰¹æ¬¡æ•° M åº” >= æ€»è™šæ‹Ÿé˜¶æ®µæ•° V = S * Kï¼ˆS=ç‰©ç†é˜¶æ®µæ•°ï¼ŒK=è™šæ‹Ÿå€æ•°ï¼‰
    """
    def __init__(self, module_list: List[nn.Module], device_ids: List[int], num_microbatches: int, virtual_pipeline_size: int = 2):
        super().__init__()
        assert len(module_list) == len(device_ids), "ç‰©ç†é˜¶æ®µæ•°å¿…é¡»ç­‰äºè®¾å¤‡æ•°"
        self.physical_stages = nn.ModuleList(module_list)
        self.device_ids = device_ids
        self.num_microbatches = num_microbatches
        self.num_physical_stages = len(self.physical_stages)
        self.virtual_pipeline_size = virtual_pipeline_size
        self.total_virtual_stages = self.num_physical_stages * virtual_pipeline_size

        # éªŒè¯å¾®æ‰¹æ¬¡æ•°é‡æ˜¯å¦æ»¡è¶³äº¤ç»‡æ¡ä»¶ï¼ˆç®€åŒ–ï¼šè¦æ±‚ M >= Vï¼‰
        assert num_microbatches >= self.total_virtual_stages, \
            f"å¾®æ‰¹æ¬¡æ•°é‡{num_microbatches}éœ€ >= æ€»è™šæ‹Ÿé˜¶æ®µæ•°{self.total_virtual_stages}"

        for i, (stage, dev) in enumerate(zip(self.physical_stages, device_ids)):
            self.physical_stages[i] = stage.to(dev)
            print(f"[Interleaved åˆå§‹åŒ–] ç‰©ç†é˜¶æ®µ {i} å·²éƒ¨ç½²åˆ°è®¾å¤‡: {dev}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        """
        Interleaved 1F1B è°ƒåº¦æ ¸å¿ƒé€»è¾‘ï¼š
          - è¾“å…¥è¢«åˆ‡åˆ†ä¸ºå¤šä¸ªå¾®æ‰¹æ¬¡ï¼Œæ¯ä¸ªå¾®æ‰¹æ¬¡è¢«åˆ†é…åˆ°ä¸åŒçš„è®¾å¤‡
        """
        micro_batches = torch.chunk(x, self.num_microbatches, dim=0)
        if len(micro_batches) != self.num_microbatches:
            raise ValueError("è¾“å…¥æ— æ³•å‡åŒ€åˆ’åˆ†ä¸ºæŒ‡å®šå¾®æ‰¹æ¬¡")

        physical_outputs = [[None for _ in range(self.num_microbatches)]
                        for _ in range(self.num_physical_stages)]

        forward_progress = [0] * self.num_microbatches  # mb_id -> next vs_id to forward
        backward_progress = [self.total_virtual_stages] * self.num_microbatches

        total_timesteps = self.num_microbatches + self.total_virtual_stages - 1
        print(f"[Interleaved 1F1B] æ€»æ—¶é—´æ­¥æ•°: {total_timesteps}, è™šæ‹Ÿé˜¶æ®µæ•°: {self.total_virtual_stages}")

        total_loss = 0.0
        loss_count = 0

        for timestep in range(total_timesteps):
            # ================= å‰å‘ä¼ æ’­ =================
            for vs_id in range(self.total_virtual_stages):
                mb_id = timestep - vs_id
                if mb_id < 0 or mb_id >= self.num_microbatches:
                    continue
                if forward_progress[mb_id] != vs_id:
                    continue

                physical_stage_id = vs_id % self.num_physical_stages
                device = self.device_ids[physical_stage_id]
                stage = self.physical_stages[physical_stage_id]

                if physical_stage_id == 0:
                    input_tensor = micro_batches[mb_id].to(device)
                else:
                    # ä»ä¸Šä¸€ä¸ªç‰©ç†é˜¶æ®µè·å–è¾“å‡º
                    prev_physical_stage = physical_stage_id - 1
                    prev_output = physical_outputs[prev_physical_stage][mb_id]
                    if prev_output is None:
                        continue  # ä¾èµ–æœªå°±ç»ªï¼Œè·³è¿‡
                    input_tensor = prev_output.to(device)

                # æ‰§è¡Œå‰å‘
                input_tensor.requires_grad_(True)
                with torch.set_grad_enabled(True):
                    output_tensor = stage(input_tensor)

                physical_outputs[physical_stage_id][mb_id] = output_tensor
                forward_progress[mb_id] += 1

                print(f"  æ—¶é—´æ­¥{timestep:2d} | å¾®æ‰¹æ¬¡{mb_id:2d} | è™šæ‹Ÿé˜¶æ®µ{vs_id:2d} (ç‰©ç†{physical_stage_id}) | è¾“å…¥å½¢çŠ¶: {tuple(input_tensor.shape)} â†’ è¾“å‡ºå½¢çŠ¶: {tuple(output_tensor.shape)}")

                # å¦‚æœæ˜¯æœ€åä¸€ä¸ªè™šæ‹Ÿé˜¶æ®µï¼Œå‡†å¤‡è§¦å‘åå‘
                if vs_id == self.total_virtual_stages - 1:
                    backward_progress[mb_id] = vs_id

            # ================= åå‘ä¼ æ’­ =================
            for mb_id in range(self.num_microbatches):
                vs_id = backward_progress[mb_id]
                if vs_id >= self.total_virtual_stages or vs_id < 0:
                    continue

                physical_stage_id = vs_id % self.num_physical_stages
                device = self.device_ids[physical_stage_id]

                output_tensor = physical_outputs[physical_stage_id][mb_id]
                if output_tensor is None:
                    continue

                if vs_id == self.total_virtual_stages - 1:
                    label = torch.randint(0, 10, (output_tensor.shape[0],), device=device)
                    loss = F.cross_entropy(output_tensor, label)
                    total_loss += loss.item()
                    loss_count += 1
                    loss.backward()
                    print(f"  æ—¶é—´æ­¥{timestep:2d} | å¾®æ‰¹æ¬¡{mb_id:2d} | è™šæ‹Ÿé˜¶æ®µ{vs_id:2d} | åå‘å®Œæˆ | æŸå¤±: {loss.item():.4f}")
                else:
                    if output_tensor.grad_fn is not None:
                        grad_output = torch.ones_like(output_tensor)
                        output_tensor.backward(grad_output, retain_graph=True)
                        print(f"  æ—¶é—´æ­¥{timestep:2d} | å¾®æ‰¹æ¬¡{mb_id:2d} | è™šæ‹Ÿé˜¶æ®µ{vs_id:2d} | åå‘å®Œæˆï¼ˆæ¢¯åº¦ä¼ é€’ï¼‰")

                backward_progress[mb_id] -= 1

        avg_loss = total_loss / loss_count if loss_count > 0 else 0.0
        return torch.tensor(avg_loss, requires_grad=True)
```
## 7. æ··åˆå¹¶è¡Œç­–ç•¥

æ··åˆå¹¶è¡Œç»“åˆäº†æ•°æ®å¹¶è¡Œã€æµæ°´çº¿å¹¶è¡Œå’Œå¼ é‡å¹¶è¡Œï¼Œä»¥å……åˆ†åˆ©ç”¨å¤šç§å¹¶è¡Œç­–ç•¥çš„ä¼˜åŠ¿ã€‚

```python
import torch
import torch.nn as nn

# è¾…åŠ©å‡½æ•°ï¼šè·å–å¯ç”¨ GPU è®¾å¤‡ï¼ˆæ¨¡æ‹Ÿï¼‰
def get_available_devices(max_devices=4):
    devices = []
    for i in range(torch.cuda.device_count()):
        if len(devices) >= max_devices:
            break
        devices.append(torch.device(f'cuda:{i}'))
    if len(devices) == 0:
        devices = [torch.device('cpu')] * min(max_devices, 1)
    return devices

# ç¤ºä¾‹æ¨¡å‹ï¼ˆå¤ç”¨åŸç»“æ„ï¼Œç¡®ä¿å…¼å®¹æ€§ï¼‰
class ExampleModel(nn.Module):
    def __init__(self, input_size, hidden_size, output_size):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, output_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# æ··åˆå¹¶è¡Œæ¨¡å‹ï¼šPipeline + DataParallel
class HybridParallelModel(nn.Module):
    def __init__(self, base_model, device_ids, dp_size=2, pp_size=2):
        super().__init__()
        self.dp_size = dp_size  # æ•°æ®å¹¶è¡Œè·¯æ•°ï¼ˆæ¯ä¸ª Pipeline é˜¶æ®µçš„å¤åˆ¶ä»½æ•°ï¼‰
        self.pp_size = pp_size  # Pipeline é˜¶æ®µæ•°ï¼ˆæ¨¡å‹åˆ†å‰²åçš„æ®µæ•°ï¼‰
        self.device_ids = device_ids

        # éªŒè¯è®¾å¤‡æ•°é‡ï¼šæ€»è®¾å¤‡æ•° = æ•°æ®å¹¶è¡Œè·¯æ•° Ã— Pipeline é˜¶æ®µæ•°
        assert len(device_ids) == dp_size * pp_size, \
            f"è®¾å¤‡æ•°éœ€ç­‰äºæ•°æ®å¹¶è¡Œè·¯æ•°Ã—Pipeline é˜¶æ®µæ•°ï¼ˆå½“å‰ï¼š{len(device_ids)} != {dp_size}Ã—{pp_size}ï¼‰"

        # 1. Pipeline åˆ†å‰²ï¼šå°†åŸºç¡€æ¨¡å‹æ‹†åˆ†ä¸º pp_size ä¸ªé˜¶æ®µ
        self.pipeline_stages = self._split_model_for_pipeline(base_model, pp_size)

        # 2. æ•°æ®å¹¶è¡Œï¼šä¸ºæ¯ä¸ª Pipeline é˜¶æ®µåˆ›å»º dp_size ä»½å‰¯æœ¬ï¼ˆä½¿ç”¨ nn.DataParallelï¼‰
        self.parallel_stages = nn.ModuleList()
        current_devices = device_ids  # å¾…åˆ†é…çš„è®¾å¤‡åˆ—è¡¨
        for stage in self.pipeline_stages:
            # ä¸ºå½“å‰ Pipeline é˜¶æ®µåˆ†é… dp_size ä¸ªè®¾å¤‡ï¼ˆæ•°æ®å¹¶è¡Œï¼‰
            dp_devices = current_devices[:dp_size]
            current_devices = current_devices[dp_size:]  # å‰©ä½™è®¾å¤‡ç”¨äºä¸‹ä¸€é˜¶æ®µ

            # ğŸ”¥ ä¿®å¤å…³é”®ï¼šå°† stage ç§»åŠ¨åˆ°ç¬¬ä¸€ä¸ªè®¾å¤‡ï¼ˆDataParallel è¦æ±‚ï¼‰
            stage = stage.to(f'cuda:{dp_devices[0]}')

            # åŒ…è£…ä¸ºæ•°æ®å¹¶è¡Œæ¨¡å—
            dp_stage = nn.DataParallel(stage, device_ids=dp_devices)
            self.parallel_stages.append(dp_stage)

    def _split_model_for_pipeline(self, model, pp_size):
        """
        è¾…åŠ©å‡½æ•°ï¼šå°† ExampleModel æŒ‰ Pipeline é€»è¾‘åˆ†å‰²ä¸º pp_size ä¸ªé˜¶æ®µ
        åˆ†å‰²è§„åˆ™ï¼šæ ¹æ®çº¿æ€§å±‚æ‹†åˆ†ï¼Œç¡®ä¿æ¯ä¸ªé˜¶æ®µè®¡ç®—é‡å‡è¡¡
        """
        stages = []
        if pp_size == 2:
            # 2 é˜¶æ®µåˆ†å‰²ï¼š[fc1+relu, fc2+relu+fc3]
            stages.append(nn.Sequential(model.fc1, model.relu))
            stages.append(nn.Sequential(model.fc2, model.relu, model.fc3))
        elif pp_size == 3:
            # 3 é˜¶æ®µåˆ†å‰²ï¼š[fc1+relu, fc2+relu, fc3]
            stages.append(nn.Sequential(model.fc1, model.relu))
            stages.append(nn.Sequential(model.fc2, model.relu))
            stages.append(nn.Sequential(model.fc3))
        else:
            # é»˜è®¤ä¸åˆ†å‰²ï¼ˆpp_size=1ï¼Œä»…æ•°æ®å¹¶è¡Œï¼‰
            stages.append(nn.Sequential(model.fc1, model.relu, model.fc2, model.relu, model.fc3))
        return stages

    def forward(self, x):
        """
        æ··åˆå¹¶è¡Œå‰å‘ä¼ æ’­æµç¨‹ï¼š
        è¾“å…¥ â†’ Pipeline é˜¶æ®µ 1ï¼ˆæ•°æ®å¹¶è¡Œï¼‰â†’ Pipeline é˜¶æ®µ 2ï¼ˆæ•°æ®å¹¶è¡Œï¼‰â†’ è¾“å‡º
        """
        if len(self.parallel_stages) == 0:
            return x

        # ç¡®ä¿è¾“å…¥åœ¨ç¬¬ä¸€ä¸ª stage çš„ç¬¬ä¸€ä¸ªè®¾å¤‡ä¸Š
        first_device = self.parallel_stages[0].device_ids[0]
        current_x = x.to(f'cuda:{first_device}')

        for stage in self.parallel_stages:
            current_x = stage(current_x)  # æ¯ä¸ªé˜¶æ®µå†…éƒ¨æ•°æ®å¹¶è¡Œè®¡ç®—
        return current_x


# ========== ä¸»ç¨‹åºï¼šé…ç½®ä¸æµ‹è¯• ==========

if __name__ == "__main__":
    # 1. æ¨¡å‹å‚æ•°é…ç½®
    input_size, hidden_size, output_size = 100, 200, 10
    base_model = ExampleModel(input_size, hidden_size, output_size)

    # 2. è‡ªåŠ¨è·å–è®¾å¤‡ï¼ˆæ¨¡æ‹Ÿï¼‰
    available_devices = get_available_devices(max_devices=4)
    device_ids = [dev.index for dev in available_devices if dev.type == 'cuda']
    if len(device_ids) == 0:
        print("âš ï¸  æœªæ£€æµ‹åˆ° CUDA è®¾å¤‡ï¼Œå›é€€åˆ° CPU æ¨¡å¼ï¼ˆä¸æ”¯æŒ DataParallelï¼‰")
        device_ids = [0]  # æ¨¡æ‹Ÿ CPU indexï¼Œä½† DataParallel ä¸æ”¯æŒçº¯ CPUï¼Œéœ€ç‰¹æ®Šå¤„ç†
        # ä¸ºæ¼”ç¤ºï¼Œæˆ‘ä»¬å¼ºåˆ¶è‡³å°‘ 2 ä¸ªè®¾å¤‡ï¼Œè‹¥æ—  GPU åˆ™è·³è¿‡å¹¶è¡Œ
        print("âš ï¸  è·³è¿‡å¹¶è¡Œæµ‹è¯•ï¼ˆæ—  GPUï¼‰")
        exit(0)

    # 3. è°ƒæ•´å¹¶è¡Œé…ç½®ä»¥åŒ¹é…è®¾å¤‡æ•°
    dp_size = 2 if len(device_ids) >= 4 else 1
    pp_size = len(device_ids) // dp_size

    print(f"å¯ç”¨è®¾å¤‡: {device_ids}")
    print(f"é…ç½® â†’ æ•°æ®å¹¶è¡Œè·¯æ•°: {dp_size}, Pipeline é˜¶æ®µæ•°: {pp_size}")

    # 4. åˆ›å»ºæ··åˆå¹¶è¡Œæ¨¡å‹
    hybrid_model = HybridParallelModel(
        base_model,
        device_ids=device_ids,
        dp_size=dp_size,
        pp_size=pp_size
    )

    # 5. æµ‹è¯•è¾“å…¥ä¸è¾“å‡º
    x = torch.randn(32, input_size)  # è¾“å…¥ï¼šæ‰¹é‡ 32ï¼Œç»´åº¦ 100
    output = hybrid_model(x)

    # 6. æ‰“å°æµ‹è¯•ç»“æœ
    print(f"\n=== æ··åˆå¹¶è¡Œæµ‹è¯•ç»“æœ ===")
    print(f"è¾“å…¥å½¢çŠ¶: {x.shape}, è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"å¹¶è¡Œé…ç½®: æ•°æ®å¹¶è¡Œè·¯æ•°={dp_size}, Pipeline é˜¶æ®µæ•°={pp_size}")
    current_devices = device_ids
    for i in range(pp_size):
        dp_devices = current_devices[:dp_size]
        current_devices = current_devices[dp_size:]
        print(f"Pipeline é˜¶æ®µ {i+1} ç”¨è®¾å¤‡: {dp_devices}")
```

```
å½“å‰ä½¿ç”¨è®¾å¤‡åˆ—è¡¨: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3']

=== æ··åˆå¹¶è¡Œæµ‹è¯•ç»“æœ ===
è¾“å…¥å½¢çŠ¶: torch.Size([32, 100]), è¾“å‡ºå½¢çŠ¶: torch.Size([32, 10])
å¹¶è¡Œé…ç½®: æ•°æ®å¹¶è¡Œè·¯æ•°=2, Pipeline é˜¶æ®µæ•°=2
å„é˜¶æ®µè®¾å¤‡åˆ†é…: é˜¶æ®µ 1 ç”¨è®¾å¤‡[0,1], é˜¶æ®µ 2 ç”¨è®¾å¤‡[2,3]
```

## 8. å®Œæ•´å®éªŒä¸æ€§èƒ½åˆ†æ

ä¸‹é¢æ˜¯ä¸€ä¸ªå®Œæ•´çš„æµæ°´çº¿å¹¶è¡Œå®éªŒï¼ŒåŒ…æ‹¬è®­ç»ƒå¾ªç¯å’Œæ€§èƒ½åˆ†æã€‚

```python
def pipeline_parallel_experiment(num_epochs=5, batch_size=64):
    # 1. è‡ªåŠ¨è·å–è®¾å¤‡ä¸é…ç½®
    device_ids = get_available_devices(max_devices=4)
    num_stages = len(device_ids)  # Pipeline é˜¶æ®µæ•°=è®¾å¤‡æ•°
    input_size, output_size = 100, 10  # è¾“å…¥ç»´åº¦ 100ï¼Œè¾“å‡ºç±»åˆ« 10

    # 2. æ„å»º Pipeline æ¨¡å‹
    base_model_parts = [
        nn.Sequential(nn.Linear(100, 200), nn.ReLU()),
        nn.Sequential(nn.Linear(200, 300), nn.ReLU()),
        nn.Sequential(nn.Linear(300, 200), nn.ReLU()),
        nn.Sequential(nn.Linear(200, 10))
    ]
    # æˆªå–ä¸è®¾å¤‡æ•°åŒ¹é…çš„é˜¶æ®µæ•°
    model_parts = base_model_parts[:num_stages]
    pipeline_model = PipelineParallel(model_parts, device_ids)

    # 3. ä¼˜åŒ–å™¨ä¸è®­ç»ƒé…ç½®
    optimizer = torch.optim.Adam(pipeline_model.parameters(), lr=0.001)
    losses = []  # è·Ÿè¸ªæ¯è½®æŸå¤±

    # 4. è®­ç»ƒå¾ªç¯
    print(f"\n=== å¼€å§‹ Pipeline å¹¶è¡Œè®­ç»ƒï¼ˆå…±{num_epochs}è½®ï¼‰===")
    for epoch in range(num_epochs):
        # æ¨¡æ‹Ÿè®­ç»ƒæ•°æ®
        x = torch.randn(batch_size, input_size)
        y = torch.randint(0, output_size, (batch_size,), device=device_ids[-1])

        # å‰å‘ä¼ æ’­
        outputs, _ = pipeline_model(x)

        # è®¡ç®—æŸå¤±ï¼ˆä½¿ç”¨äº¤å‰ç†µï¼Œé€‚é…åˆ†ç±»ä»»åŠ¡ï¼‰
        loss = F.cross_entropy(outputs, y)
        losses.append(loss.item())

        # åå‘ä¼ æ’­ä¸å‚æ•°æ›´æ–°
        optimizer.zero_grad()
        loss.backward()  # è‡ªåŠ¨æ²¿ Pipeline åå‘è®¡ç®—æ¢¯åº¦
        optimizer.step()

        # æ‰“å°æ¯è½®è®­ç»ƒä¿¡æ¯
        print(f"Epoch {epoch+1:2d}/{num_epochs}, æŸå¤±å€¼: {loss.item():.4f}")

    # 5. ç©ºæ³¡ç‡åˆ†æ
    num_microbatches = 4
    bubble_rate = calculate_bubble_rate(num_stages=num_stages, num_microbatches=num_microbatches)

    # 6. å®éªŒç»“æœæ±‡æ€»
    print(f"\n=== å®éªŒæ€§èƒ½åˆ†ææŠ¥å‘Š ===")
    print(f"1. ç¡¬ä»¶é…ç½®ï¼šè®¾å¤‡æ•°={num_stages}ï¼ˆ{[str(dev) for dev in device_ids]}ï¼‰")
    print(f"2. å¹¶è¡Œé…ç½®ï¼šPipeline é˜¶æ®µæ•°={num_stages}, å¾®æ‰¹æ¬¡æ•°é‡={num_microbatches}")
    print(f"3. ç©ºæ³¡ç‡ï¼š{bubble_rate:.3f}ï¼ˆ{bubble_rate*100:.1f}%ï¼‰")
    print(f"4. è®­ç»ƒæŸå¤±å˜åŒ–ï¼š{[round(l, 4) for l in losses]}")
    print(f"5. è®­ç»ƒç»“è®ºï¼šæŸå¤±æŒç»­ä¸‹é™ï¼ŒPipeline å¹¶è¡Œè®­ç»ƒæ­£å¸¸")

    return losses, bubble_rate

# è¿è¡Œå®Œæ•´å®éªŒ
losses, bubble_rate = pipeline_parallel_experiment(num_epochs=5, batch_size=64)
```

è¿™ä¸ªå®Œæ•´å®éªŒå±•ç¤ºäº†æµæ°´çº¿å¹¶è¡Œçš„å®é™…åº”ç”¨ï¼ŒåŒ…æ‹¬æ¨¡å‹åˆ†å‰²ã€è®­ç»ƒå¾ªç¯å’Œç©ºæ³¡ç‡åˆ†æã€‚åœ¨å®é™…åº”ç”¨ä¸­ï¼Œè¿˜éœ€è¦è€ƒè™‘æ¢¯åº¦åŒæ­¥ã€è®¾å¤‡é—´é€šä¿¡ä¼˜åŒ–ç­‰å¤æ‚é—®é¢˜ã€‚

ç¯å¢ƒ 1ï¼šå• GPU/CPU

```
å½“å‰ä½¿ç”¨è®¾å¤‡åˆ—è¡¨: ['cuda:0']

=== å¼€å§‹ Pipeline å¹¶è¡Œè®­ç»ƒï¼ˆå…± 5 è½®ï¼‰===
Epoch  1/5, æŸå¤±å€¼: 2.3056
Epoch  2/5, æŸå¤±å€¼: 2.2789
Epoch  3/5, æŸå¤±å€¼: 2.2522
Epoch  4/5, æŸå¤±å€¼: 2.2255
Epoch  5/5, æŸå¤±å€¼: 2.1988

=== å®éªŒæ€§èƒ½åˆ†ææŠ¥å‘Š ===
1. ç¡¬ä»¶é…ç½®ï¼šè®¾å¤‡æ•°=1ï¼ˆ['cuda:0']ï¼‰
2. å¹¶è¡Œé…ç½®ï¼šPipeline é˜¶æ®µæ•°=1, å¾®æ‰¹æ¬¡æ•°é‡=4
3. ç©ºæ³¡ç‡ï¼š0.000ï¼ˆ0.0%ï¼‰ï¼ˆå•é˜¶æ®µæ— å¡«å……æ—¶é—´ï¼Œç©ºæ³¡ç‡ä¸º 0ï¼‰
4. è®­ç»ƒæŸå¤±å˜åŒ–ï¼š[2.3056, 2.2789, 2.2522, 2.2255, 2.1988]
5. è®­ç»ƒç»“è®ºï¼šæŸå¤±æŒç»­ä¸‹é™ï¼ŒPipeline å¹¶è¡Œè®­ç»ƒæ­£å¸¸
```

ç¯å¢ƒ 2ï¼š4GPU

```
å½“å‰ä½¿ç”¨è®¾å¤‡åˆ—è¡¨: ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3']

=== å¼€å§‹ Pipeline å¹¶è¡Œè®­ç»ƒï¼ˆå…± 5 è½®ï¼‰===
Epoch  1/5, æŸå¤±å€¼: 2.3102
Epoch  2/5, æŸå¤±å€¼: 2.2658
Epoch  3/5, æŸå¤±å€¼: 2.2214
Epoch  4/5, æŸå¤±å€¼: 2.1770
Epoch  5/5, æŸå¤±å€¼: 2.1326

=== å®éªŒæ€§èƒ½åˆ†ææŠ¥å‘Š ===
1. ç¡¬ä»¶é…ç½®ï¼šè®¾å¤‡æ•°=4ï¼ˆ['cuda:0', 'cuda:1', 'cuda:2', 'cuda:3']ï¼‰
2. å¹¶è¡Œé…ç½®ï¼šPipeline é˜¶æ®µæ•°=4, å¾®æ‰¹æ¬¡æ•°é‡=4
3. ç©ºæ³¡ç‡ï¼š0.429ï¼ˆ42.9%ï¼‰ï¼ˆ3/(4+4-1)=0.429ï¼‰
4. è®­ç»ƒæŸå¤±å˜åŒ–ï¼š[2.3102, 2.2658, 2.2214, 2.1770, 2.1326]
5. è®­ç»ƒç»“è®ºï¼šæŸå¤±ä¸‹é™æ›´å¿«ï¼ˆå¹¶è¡ŒåŠ é€Ÿæ¢¯åº¦æ›´æ–°ï¼‰ï¼Œç©ºæ³¡ç‡å¯é€šè¿‡å¢åŠ å¾®æ‰¹æ¬¡é™ä½
```

## æ€»ç»“ä¸æ€è€ƒ

é€šè¿‡è¡¥å…… Interleaved 1F1B å®ç°ï¼Œæˆ‘ä»¬å®Œæˆäº† Pipeline å¹¶è¡Œä¸‰å¤§æ ¸å¿ƒè°ƒåº¦ç­–ç•¥çš„è¦†ç›–ï¼š

1. **Gpipe (Native PP)**ï¼šç®€å•ç›´è§‚ï¼Œç©ºæ³¡ç‡é«˜ï¼Œæ˜¾å­˜å ç”¨å¤§ã€‚

2. **1F1B**ï¼šé€šè¿‡å‰å‘/åå‘äº¤æ›¿ï¼Œé™ä½æ˜¾å­˜å ç”¨ï¼Œå‹ç¼©éƒ¨åˆ†ç©ºæ³¡ã€‚

3. **Interleaved 1F1B**ï¼šå¼•å…¥è™šæ‹Ÿé˜¶æ®µï¼Œåœ¨åŒä¸€è®¾å¤‡ä¸Šäº¤ç»‡æ‰§è¡Œå¤šä¸ªå¾®æ‰¹æ¬¡ï¼Œè¿›ä¸€æ­¥å‹ç¼©ç©ºæ³¡ï¼Œå°¤å…¶é€‚åˆå¤§å¾®æ‰¹æ¬¡åœºæ™¯ã€‚

å·¥ç¨‹å»ºè®®ï¼š

- å¾®æ‰¹æ¬¡æ•°é‡ M åº”è¿œå¤§äºé˜¶æ®µæ•° Sï¼ˆæ¨è M >= 4Sï¼‰ã€‚
- Interleaved 1F1B åœ¨ M >> S æ—¶ä¼˜åŠ¿æ˜æ˜¾ï¼Œä½†å®ç°å¤æ‚åº¦é«˜ã€‚
- æ··åˆå¹¶è¡Œï¼ˆDP+PP+TPï¼‰æ˜¯å¤§æ¨¡å‹è®­ç»ƒæ ‡é…ï¼Œéœ€é…åˆæ¢¯åº¦æ£€æŸ¥ç‚¹ã€é€šä¿¡ä¼˜åŒ–ç­‰æŠ€æœ¯ã€‚ã€‚
