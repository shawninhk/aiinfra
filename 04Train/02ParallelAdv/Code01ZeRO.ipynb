{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed035d7",
   "metadata": {},
   "source": [
    "<!--Copyright © ZOMI 适用于[License](https://github.com/Infrasys-AI/AIInfra)版权许可-->\n",
    "\n",
    "# CODE 01: ZeRO 显存优化实践\n",
    "\n",
    "在大模型训练过程中，显存限制是主要瓶颈之一。微软开发的**ZeRO**（Zero Redundancy Optimizer）技术通过消除数据并行中的显存冗余，显著降低了训练大模型所需的显存。本实验将深入探讨 ZeRO 的各级优化技术，通过实际代码演示和分析，理解不同级别的 ZeRO 如何实现显存优化。\n",
    "\n",
    "## 1. 模型显存占用分析\n",
    "\n",
    "在深度学习训练中，显存主要被以下组件占用：\n",
    "\n",
    "- **模型参数**（Parameters）：模型的可学习权重\n",
    "- **梯度**（Gradients）：反向传播计算的梯度\n",
    "- **优化器状态**（Optimizer States）：如 Adam 优化器中的动量和方差\n",
    "- **激活值**（Activations）：前向传播的中间计算结果\n",
    "\n",
    "对于使用 Adam 优化器的模型，显存占用可估算为："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0aff2c0",
   "metadata": {
    "attributes": {
     "classes": [
      "text"
     ],
     "id": ""
    }
   },
   "source": [
    "```\n",
    "总显存 = 参数显存 + 梯度显存 + 优化器状态显存 + 激活值显存\n",
    "参数显存 = 参数量 × 4 字节（FP32）\n",
    "梯度显存 = 参数量 × 4 字节（FP32）\n",
    "优化器状态显存 = 参数量 × 16 字节（FP32 Adam）\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97271d95",
   "metadata": {},
   "source": [
    "显存占用分析工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e400b934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU0] 初始状态: 已分配: 0.64GB, 变化: +0.64GB\n",
      "[GPU0] 模型创建后: 已分配: 0.77GB, 变化: +0.13GB\n",
      "[GPU0] 优化器创建后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 数据加载后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 前向传播后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 反向传播后: 已分配: 0.89GB, 变化: +0.12GB\n",
      "[GPU0] 优化器更新后: 已分配: 1.14GB, 变化: +0.25GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import defaultdict\n",
    "\n",
    "class MemoryAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.memory_stats = defaultdict(list)\n",
    "        self.previous_allocated = 0\n",
    "\n",
    "    def record(self, tag='', device=0):\n",
    "        allocated = torch.cuda.memory_allocated(device) / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved(device) / 1024**3\n",
    "        delta = allocated - self.previous_allocated\n",
    "        self.previous_allocated = allocated\n",
    "\n",
    "        self.memory_stats['allocated'].append(allocated)\n",
    "        self.memory_stats['reserved'].append(reserved)\n",
    "        self.memory_stats['delta'].append(delta)\n",
    "\n",
    "        print(f\"[GPU{device}] {tag}: 已分配: {allocated:.2f}GB, 变化: {delta:+.2f}GB\")\n",
    "        return allocated\n",
    "\n",
    "\n",
    "def create_model(hidden_size=2048, num_layers=8):\n",
    "    layers = []\n",
    "    for _ in range(num_layers):\n",
    "        layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "        layers.append(nn.ReLU())\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# 执行显存分析\n",
    "def analyze_memory():\n",
    "    # 确保使用 GPU\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA 不可用，无法进行显存分析\")\n",
    "        return\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    analyzer = MemoryAnalyzer()\n",
    "\n",
    "    # 记录初始状态\n",
    "    analyzer.record(\"初始状态\")\n",
    "\n",
    "    # 创建模型\n",
    "    model = create_model().cuda()\n",
    "    analyzer.record(\"模型创建后\")\n",
    "\n",
    "    # 创建优化器\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    analyzer.record(\"优化器创建后\")\n",
    "\n",
    "    # 模拟数据\n",
    "    inputs = torch.randn(32, 2048).cuda()\n",
    "    targets = torch.randn(32, 2048).cuda()\n",
    "    analyzer.record(\"数据加载后\")\n",
    "\n",
    "    # 前向传播\n",
    "    outputs = model(inputs)\n",
    "    loss = F.mse_loss(outputs, targets)\n",
    "    analyzer.record(\"前向传播后\")\n",
    "\n",
    "    # 反向传播\n",
    "    loss.backward()\n",
    "    analyzer.record(\"反向传播后\")\n",
    "\n",
    "    # 优化器步骤\n",
    "    optimizer.step()\n",
    "    analyzer.record(\"优化器更新后\")\n",
    "\n",
    "    return analyzer.memory_stats\n",
    "\n",
    "# 执行分析\n",
    "memory_stats = analyze_memory()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d37206",
   "metadata": {},
   "source": [
    "通过这个分析工具，我们可以清楚地看到在每个训练阶段显存的使用情况变化。在实际的大模型训练中，这些显存占用会成倍增长，凸显了 ZeRO 优化的必要性。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdae504",
   "metadata": {},
   "source": [
    "```\n",
    "初始状态: 已分配: 0.00GB, 变化: +0.00GB\n",
    "模型创建后: 已分配: 0.13GB, 变化: +0.13GB\n",
    "优化器创建后: 已分配: 0.13GB, 变化: +0.00GB\n",
    "数据加载后: 已分配: 0.13GB, 变化: +0.00GB\n",
    "前向传播后: 已分配: 0.14GB, 变化: +0.01GB\n",
    "反向传播后: 已分配: 0.27GB, 变化: +0.13GB\n",
    "优化器更新后: 已分配: 0.52GB, 变化: +0.25GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff08427",
   "metadata": {},
   "source": [
    "## 2. ZeRO-1: 优化器状态分片\n",
    "\n",
    "ZeRO-1 通过将优化器状态分片到多个 GPU 上来减少显存占用。在传统数据并行中，每个 GPU 都保存完整的优化器状态副本，这造成了大量的显存冗余。\n",
    "\n",
    "ZeRO-1 的核心思想是：每个 GPU 只保存一部分优化器状态，当需要更新参数时，通过集合通信操作获取完整的梯度信息。\n",
    "\n",
    "数学表达上，对于 Adam 优化器，每个 GPU 原本需要存储：\n",
    "\n",
    "- 参数：$Θ$\n",
    "- 梯度：$∇Θ$\n",
    "- 动量：$m$\n",
    "- 方差：$v$\n",
    "\n",
    "ZeRO-1 分片后，每个 GPU 只存储：\n",
    "\n",
    "- 完整参数：$Θ$\n",
    "- 完整梯度：$∇Θ$\n",
    "- 1/N 的动量：$m_i$\n",
    "- 1/N 的方差：$v_i$\n",
    "\n",
    "其中 N 是 GPU 数量。\n",
    "\n",
    "![](./images/Code01ZeRO01.png)\n",
    "\n",
    "ZeRO-1 优化器状态分片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ebac3fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "测试 ZeRO-1 模拟 (GPU 数量: 1)\n",
      "==================================================\n",
      "[GPU0] 初始化后: 已分配: 0.77GB, 变化: +0.77GB\n",
      "[GPU0] 训练一步后: 已分配: 1.15GB, 变化: +0.38GB\n",
      "[GPU0] 峰值显存: 1.27 GB\n",
      "→ 所有 GPU 中最大显存: 1.27 GB\n",
      "\n",
      "跳过多 GPU 测试（需要 4 卡，当前 1 卡）\n"
     ]
    }
   ],
   "source": [
    "class Zero1OptimizerSim:\n",
    "    \"\"\"\n",
    "    模拟 ZeRO-1：在多 GPU 上分片参数和优化器状态\n",
    "    注意：仅用于显存分析，不支持完整训练（无梯度同步）\n",
    "    \"\"\"\n",
    "    def __init__(self, model, num_gpus=1, optimizer_class=torch.optim.Adam, **kwargs):\n",
    "        self.num_gpus = num_gpus\n",
    "        self.optimizer_class = optimizer_class\n",
    "        self.optimizer_kwargs = kwargs\n",
    "\n",
    "        if num_gpus == 1:\n",
    "            # 单 GPU：所有参数留在 GPU 0\n",
    "            self.model = model.cuda(0)\n",
    "            self.param_groups = [list(self.model.parameters())]\n",
    "            self.devices = [0]\n",
    "        else:\n",
    "            # 多 GPU：将参数分片并分配到不同 GPU\n",
    "            self._shard_model_to_gpus(model)\n",
    "\n",
    "        # 为每个 GPU 上的参数分片创建优化器\n",
    "        self.optimizers = []\n",
    "        for i, params in enumerate(self.param_groups):\n",
    "            opt = self.optimizer_class(params, **self.optimizer_kwargs)\n",
    "            self.optimizers.append(opt)\n",
    "\n",
    "    def _shard_model_to_gpus(self, model):\n",
    "        \"\"\"将模型参数均匀分片到多个 GPU\"\"\"\n",
    "        # 获取所有参数（按模块顺序）\n",
    "        all_params = list(model.parameters())\n",
    "        n_params = len(all_params)\n",
    "\n",
    "        # 计算每 GPU 分配的参数数量\n",
    "        params_per_gpu = n_params // self.num_gpus\n",
    "        remainder = n_params % self.num_gpus\n",
    "\n",
    "        self.param_groups = []\n",
    "        self.devices = list(range(self.num_gpus))\n",
    "        start = 0\n",
    "\n",
    "        for i in range(self.num_gpus):\n",
    "            # 分配更多参数给前几个 GPU（处理 remainder）\n",
    "            end = start + params_per_gpu + (1 if i < remainder else 0)\n",
    "            shard_params = all_params[start:end]\n",
    "\n",
    "            # 将这些参数移动到 GPU i\n",
    "            for p in shard_params:\n",
    "                p.data = p.data.to(f'cuda:{i}')\n",
    "                if p.grad is not None:\n",
    "                    p.grad = p.grad.to(f'cuda:{i}')\n",
    "\n",
    "            self.param_groups.append(shard_params)\n",
    "            start = end\n",
    "\n",
    "    def zero_grad(self):\n",
    "        if self.num_gpus == 1:\n",
    "            for p in self.model.parameters():\n",
    "                if p.grad is not None:\n",
    "                    p.grad.zero_()\n",
    "        else:\n",
    "            for params in self.param_groups:\n",
    "                for p in params:\n",
    "                    if p.grad is not None:\n",
    "                        p.grad.zero_()\n",
    "\n",
    "    def step(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "def test_zero1_sim(num_gpus=1):\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"CUDA 不可用\")\n",
    "        return None\n",
    "    if torch.cuda.device_count() < num_gpus:\n",
    "        print(f\"可用 GPU 数量 ({torch.cuda.device_count()}) < 请求数量 ({num_gpus})\")\n",
    "        return None\n",
    "\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"测试 ZeRO-1 模拟 (GPU 数量: {num_gpus})\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # 在 CPU 上创建模型（避免提前占用 GPU 显存）\n",
    "    model = create_model()\n",
    "\n",
    "    # 创建 ZeRO-1 优化器（会自动分片到 GPU）\n",
    "    optimizer = Zero1OptimizerSim(\n",
    "        model,\n",
    "        num_gpus=num_gpus,\n",
    "        optimizer_class=torch.optim.Adam,\n",
    "        lr=1e-3\n",
    "    )\n",
    "\n",
    "    # 分析每个 GPU 的显存\n",
    "    analyzers = {}\n",
    "    for dev in range(num_gpus):\n",
    "        torch.cuda.reset_peak_memory_stats(dev)\n",
    "        analyzer = MemoryAnalyzer()\n",
    "        analyzer.record(\"初始化后\", device=dev)\n",
    "        analyzers[dev] = analyzer\n",
    "\n",
    "    # 创建输入（放在 GPU 0，简化）\n",
    "    inputs = torch.randn(32, 2048).cuda(0)\n",
    "\n",
    "    # 前向传播（仅在 GPU 0 上运行，简化！）\n",
    "    # 注意：真实场景需将计算也分片（如 Pipeline Parallelism）\n",
    "    if num_gpus == 1:\n",
    "        outputs = optimizer.model(inputs)\n",
    "    else:\n",
    "        # 为简化，我们只在 GPU 0 上运行整个模型（不真实，但够显存分析）\n",
    "        # 真实 ZeRO-1 通常与数据并行结合，这里仅关注优化器状态分布\n",
    "        temp_model = create_model().cuda(0)\n",
    "        with torch.no_grad():\n",
    "            outputs = temp_model(inputs)\n",
    "        del temp_model\n",
    "\n",
    "    # 模拟梯度（为每个参数创建梯度）\n",
    "    if num_gpus == 1:\n",
    "        for p in optimizer.model.parameters():\n",
    "            p.grad = torch.randn_like(p.data)\n",
    "    else:\n",
    "        for i, params in enumerate(optimizer.param_groups):\n",
    "            for p in params:\n",
    "                p.grad = torch.randn_like(p.data)\n",
    "\n",
    "    # 执行优化器 step（触发优化器状态分配）\n",
    "    optimizer.step()\n",
    "\n",
    "    # 记录显存\n",
    "    for dev in range(num_gpus):\n",
    "        analyzers[dev].record(\"训练一步后\", device=dev)\n",
    "\n",
    "    # 打印每卡最大显存\n",
    "    max_mem = 0\n",
    "    for dev in range(num_gpus):\n",
    "        peak = torch.cuda.max_memory_allocated(dev) / 1024**3\n",
    "        print(f\"[GPU{dev}] 峰值显存: {peak:.2f} GB\")\n",
    "        max_mem = max(max_mem, peak)\n",
    "    print(f\"→ 所有 GPU 中最大显存: {max_mem:.2f} GB\")\n",
    "\n",
    "    return analyzer.memory_stats\n",
    "\n",
    "\n",
    "\n",
    "# 执行测试\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试单 GPU\n",
    "    mem_single = test_zero1_sim(num_gpus=1)\n",
    "\n",
    "    # 测试多 GPU（如果可用）\n",
    "    if torch.cuda.device_count() >= 4:\n",
    "        mem_multi = test_zero1_sim(num_gpus=4)\n",
    "\n",
    "        if mem_single and mem_multi:\n",
    "            print(f\"\\n{'='*50}\")\n",
    "            print(f\"显存节省效果:\")\n",
    "            print(f\"单 GPU 最大显存: {mem_single:.2f} GB\")\n",
    "            print(f\"4 GPU 最大显存: {mem_multi:.2f} GB\")\n",
    "            print(f\"理论节省比例: ~{mem_single/mem_multi:.1f}x\")\n",
    "            print(f\"{'='*50}\")\n",
    "    else:\n",
    "        print(f\"\\n跳过多 GPU 测试（需要 4 卡，当前 {torch.cuda.device_count()} 卡）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edea50a4",
   "metadata": {},
   "source": [
    "这个简化实现展示了 ZeRO-1 的核心思想：每个 GPU 只存储和更新一部分参数的优化器状态，通过通信操作确保所有 GPU 的参数保持一致。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fabfd7",
   "metadata": {},
   "source": [
    "```\n",
    "模型创建后: 已分配: 0.14GB, 变化: +0.14GB\n",
    "ZeRO-1 优化器创建后: 已分配: 0.14GB, 变化: +0.00GB\n",
    "训练一步后: 已分配: 0.52GB, 变化: +0.38GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab8870f",
   "metadata": {},
   "source": [
    "## 3. ZeRO-2: 梯度分片\n",
    "\n",
    "ZeRO-2 在 ZeRO-1 的基础上进一步优化，不仅分片优化器状态，还分片梯度。这进一步减少了显存占用，因为梯度通常与参数大小相同。\n",
    "\n",
    "![](./images/Code01ZeRO02.png)\n",
    "\n",
    "在反向传播过程中，每个 GPU 计算其分配到的参数的梯度，然后通过 Reduce-Scatter 操作聚合梯度。这样每个 GPU 只保存一部分梯度，而不是全部梯度。梯度分片的数学表达：\n",
    "\n",
    "- 传统方法：每个 GPU 存储完整梯度 $∇Θ$\n",
    "- ZeRO-2：每个 GPU 存储 1/N 的梯度 $∇Θ_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "410532f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU0] 模型创建后: 已分配: 0.77GB, 变化: +0.77GB\n",
      "[GPU0] ZeRO-2 优化器创建后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 训练一步后: 已分配: 1.14GB, 变化: +0.38GB\n"
     ]
    }
   ],
   "source": [
    "class Zero2Optimizer(Zero1Optimizer):\n",
    "    \"\"\"简化的 ZeRO-2 优化器实现，在 ZeRO-1 基础上增加梯度分片\"\"\"\n",
    "\n",
    "    def __init__(self, params, optimizer_class=torch.optim.Adam, shard_size=4, **kwargs):\n",
    "        super().__init__(params, optimizer_class, shard_size,** kwargs)\n",
    "        self.grad_shards = self._create_shards()  # 梯度分片与参数分片对应\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"执行优化步骤，只处理分片梯度\"\"\"\n",
    "        # 模拟梯度分片聚合\n",
    "        for i, shard in enumerate(self.grad_shards):\n",
    "            # 只聚合当前分片需要的梯度\n",
    "            for param in shard:\n",
    "                if param.grad is not None:\n",
    "                    # 模拟分布式梯度聚合\n",
    "                    param.grad = param.grad.contiguous()\n",
    "\n",
    "            # 更新当前分片\n",
    "            self.optimizers[i].step()\n",
    "\n",
    "# 测试 ZeRO-2 效果\n",
    "def test_zero2():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    analyzer = MemoryAnalyzer()\n",
    "\n",
    "    model = create_model().cuda()\n",
    "    analyzer.record(\"模型创建后\")\n",
    "\n",
    "    # 使用 ZeRO-2 优化器\n",
    "    optimizer = Zero2Optimizer(model.parameters(), shard_size=4, lr=1e-3)\n",
    "    analyzer.record(\"ZeRO-2 优化器创建后\")\n",
    "\n",
    "    # 简单训练步骤\n",
    "    inputs = torch.randn(32, 2048).cuda()\n",
    "    outputs = model(inputs)\n",
    "    loss = F.mse_loss(outputs, torch.randn_like(outputs))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    analyzer.record(\"训练一步后\")\n",
    "    return analyzer.memory_stats\n",
    "\n",
    "# 执行测试\n",
    "zero2_stats = test_zero2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd6a0f9",
   "metadata": {},
   "source": [
    "ZeRO-2 通过梯度分片进一步减少了显存占用，但增加了通信开销。在实际应用中，需要根据网络带宽和计算能力权衡这种权衡。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08975588",
   "metadata": {},
   "source": [
    "```\n",
    "模型创建后: 已分配: 0.13GB, 变化: +0.13GB\n",
    "ZeRO-2 优化器创建后: 已分配: 0.13GB, 变化: +0.00GB\n",
    "训练一步后: 已分配: 0.31GB, 变化: +0.18GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d40d456",
   "metadata": {},
   "source": [
    "## 4. ZeRO-3: 参数分片\n",
    "\n",
    "ZeRO-3 是 ZeRO 系列的最终形态，它不仅分片优化器状态和梯度，还分片模型参数本身。这意味着每个 GPU 只存储模型的一小部分参数，大大降低了单个 GPU 的显存需求。\n",
    "\n",
    "![](./images/Code01ZeRO03.png)\n",
    "\n",
    "ZeRO-3 的工作原理：\n",
    "\n",
    "1. 前向传播时，每个 GPU 只计算它拥有的参数部分\n",
    "2. 需要其他 GPU 的参数时，通过通信操作获取\n",
    "3. 反向传播时类似，只计算本地参数的梯度\n",
    "4. 通过精心设计的通信模式最小化通信开销\n",
    "\n",
    "参数分片的数学表达：\n",
    "\n",
    "- 传统方法：每个 GPU 存储完整参数 $Θ$\n",
    "- ZeRO-3：每个 GPU 存储 1/N 的参数 $Θ_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "aa67c7d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU0] ZeRO-3 模型创建后: 已分配: 0.67GB, 变化: +0.67GB\n",
      "[GPU0] 优化器创建后: 已分配: 0.67GB, 变化: +0.00GB\n",
      "[GPU0] 训练一步后: 已分配: 0.77GB, 变化: +0.09GB\n"
     ]
    }
   ],
   "source": [
    "class Zero3Model(nn.Module):\n",
    "    \"\"\"简化的 ZeRO-3 参数分片模型\"\"\"\n",
    "\n",
    "    def __init__(self, base_model, shard_id=0, num_shards=4):\n",
    "        super().__init__()\n",
    "        self.shard_id = shard_id\n",
    "        self.num_shards = num_shards\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        # 分片模型层\n",
    "        total_layers = len(base_model)\n",
    "        layers_per_shard = (total_layers + num_shards - 1) // num_shards\n",
    "        start = shard_id * layers_per_shard\n",
    "        end = min(start + layers_per_shard, total_layers)\n",
    "\n",
    "        # 只保留当前分片负责的层\n",
    "        for i in range(start, end):\n",
    "            self.layers.append(base_model[i])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"前向传播，只计算当前分片\"\"\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "# 测试 ZeRO-3 效果\n",
    "def test_zero3():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    analyzer = MemoryAnalyzer()\n",
    "\n",
    "    # 创建基础模型\n",
    "    base_model = create_model()\n",
    "    # 创建分片模型（只加载 1/4 的参数）\n",
    "    model = Zero3Model(base_model, shard_id=0, num_shards=4).cuda()\n",
    "    analyzer.record(\"ZeRO-3 模型创建后\")\n",
    "\n",
    "    # 优化器只需要优化部分参数\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    analyzer.record(\"优化器创建后\")\n",
    "\n",
    "    # 简单训练步骤\n",
    "    inputs = torch.randn(32, 2048).cuda()\n",
    "    outputs = model(inputs)\n",
    "    loss = F.mse_loss(outputs, torch.randn_like(outputs))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    analyzer.record(\"训练一步后\")\n",
    "    return analyzer.memory_stats\n",
    "\n",
    "# 执行测试\n",
    "zero3_stats = test_zero3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc174396",
   "metadata": {},
   "source": [
    "ZeRO-3 提供了最大的显存节省，但通信开销也最大。在实际应用中，通常需要结合各种优化技术，如通信计算重叠、梯度累积等，来平衡显存节省和训练速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb53782",
   "metadata": {},
   "source": [
    "```\n",
    "ZeRO-3 模型创建后: 已分配: 0.03GB, 变化: +0.03GB\n",
    "优化器创建后: 已分配: 0.03GB, 变化: +0.00GB\n",
    "训练一步后: 已分配: 0.11GB, 变化: +0.08GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1b4978",
   "metadata": {},
   "source": [
    "## 5. Zero Offload 技术\n",
    "\n",
    "Zero Offload 技术将优化器状态、梯度和参数卸载到 CPU 内存或 NVMe 存储，进一步扩展了可训练的模型规模。这种技术特别适合在有限 GPU 内存环境下训练超大模型。\n",
    "\n",
    "![](./images/Code01ZeRO04.png)\n",
    "\n",
    "Offload 的核心思想是利用 CPU 内存和 NVMe 存储作为 GPU 显存的扩展，通过异步数据传输和计算重叠来最小化性能影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c355a678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU0] 模型创建后: 已分配: 0.77GB, 变化: +0.77GB\n",
      "[GPU0] CPU Offload 优化器创建后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 训练一步后: 已分配: 0.89GB, 变化: +0.13GB\n"
     ]
    }
   ],
   "source": [
    "class CPUOffloadOptimizer:\n",
    "    \"\"\"简化的 CPU Offload 优化器\"\"\"\n",
    "\n",
    "    def __init__(self, params, optimizer_class=torch.optim.Adam, **kwargs):\n",
    "        self.params = list(params)\n",
    "\n",
    "        # 在 CPU 上创建参数副本和优化器\n",
    "        self.cpu_params = [p.detach().cpu().requires_grad_(False) for p in self.params]\n",
    "        self.optimizer = optimizer_class(self.cpu_params,** kwargs)\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"执行优化步骤，使用 CPU 计算\"\"\"\n",
    "        # 将梯度复制到 CPU\n",
    "        for gpu_param, cpu_param in zip(self.params, self.cpu_params):\n",
    "            if gpu_param.grad is not None:\n",
    "                cpu_param.grad = gpu_param.grad.cpu()\n",
    "\n",
    "        # 在 CPU 上更新\n",
    "        self.optimizer.step()\n",
    "\n",
    "        # 将更新后的参数复制回 GPU\n",
    "        for gpu_param, cpu_param in zip(self.params, self.cpu_params):\n",
    "            gpu_param.data.copy_(cpu_param.data)\n",
    "\n",
    "# 测试 CPU Offload 效果\n",
    "def test_cpu_offload():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    analyzer = MemoryAnalyzer()\n",
    "\n",
    "    model = create_model().cuda()\n",
    "    analyzer.record(\"模型创建后\")\n",
    "\n",
    "    # 使用 CPU Offload 优化器\n",
    "    optimizer = CPUOffloadOptimizer(model.parameters(), lr=1e-3)\n",
    "    analyzer.record(\"CPU Offload 优化器创建后\")\n",
    "\n",
    "    # 简单训练步骤\n",
    "    inputs = torch.randn(32, 2048).cuda()\n",
    "    outputs = model(inputs)\n",
    "    loss = F.mse_loss(outputs, torch.randn_like(outputs))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    analyzer.record(\"训练一步后\")\n",
    "    return analyzer.memory_stats\n",
    "\n",
    "# 执行测试\n",
    "offload_stats = test_cpu_offload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eae4922",
   "metadata": {},
   "source": [
    "```\n",
    "模型创建后: 已分配: 0.13GB, 变化: +0.13GB\n",
    "CPU Offload 优化器创建后: 已分配: 0.13GB, 变化: +0.00GB\n",
    "训练一步后: 已分配: 0.25GB, 变化: +0.12GB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aacbd31",
   "metadata": {},
   "source": [
    "## 6. 性能分析与实验结果\n",
    "\n",
    "为了验证 ZeRO 各级别的效果，我们设计了以下实验："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fe058aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 显存使用对比 (单位: GB):\n",
      "----------------------------------------\n",
      "[GPU0] 初始状态: 已分配: 0.64GB, 变化: +0.64GB\n",
      "[GPU0] 模型创建后: 已分配: 0.77GB, 变化: +0.13GB\n",
      "[GPU0] 优化器创建后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 数据加载后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 前向传播后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 反向传播后: 已分配: 0.89GB, 变化: +0.12GB\n",
      "[GPU0] 优化器更新后: 已分配: 1.14GB, 变化: +0.25GB\n",
      "\n",
      "==================================================\n",
      "测试 ZeRO-1 模拟 (GPU 数量: 1)\n",
      "==================================================\n",
      "[GPU0] 初始化后: 已分配: 0.77GB, 变化: +0.77GB\n",
      "[GPU0] 训练一步后: 已分配: 1.15GB, 变化: +0.38GB\n",
      "[GPU0] 峰值显存: 1.27 GB\n",
      "→ 所有 GPU 中最大显存: 1.27 GB\n",
      "[GPU0] 模型创建后: 已分配: 0.77GB, 变化: +0.77GB\n",
      "[GPU0] ZeRO-2 优化器创建后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 训练一步后: 已分配: 1.14GB, 变化: +0.38GB\n",
      "[GPU0] ZeRO-3 模型创建后: 已分配: 0.67GB, 变化: +0.67GB\n",
      "[GPU0] 优化器创建后: 已分配: 0.67GB, 变化: +0.00GB\n",
      "[GPU0] 训练一步后: 已分配: 0.77GB, 变化: +0.09GB\n",
      "[GPU0] 模型创建后: 已分配: 0.77GB, 变化: +0.77GB\n",
      "[GPU0] CPU Offload 优化器创建后: 已分配: 0.77GB, 变化: +0.00GB\n",
      "[GPU0] 训练一步后: 已分配: 0.89GB, 变化: +0.13GB\n",
      "基础方法: 1.14GB\n",
      "ZeRO-1: 1.15GB (-0.1% 节省)\n",
      "ZeRO-2: 1.14GB (0.0% 节省)\n",
      "ZeRO-3: 0.77GB (32.8% 节省)\n",
      "CPU Offload: 0.89GB (21.9% 节省)\n"
     ]
    }
   ],
   "source": [
    "# 汇总所有方法的显存使用情况\n",
    "def compare_methods():\n",
    "    if not torch.cuda.is_available():\n",
    "        return\n",
    "\n",
    "    print(\"\\n 显存使用对比 (单位: GB):\")\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    # 重新运行基础测试\n",
    "    baseline = analyze_memory()\n",
    "    zero1 = test_zero1_sim()\n",
    "    zero2 = test_zero2()\n",
    "    zero3 = test_zero3()\n",
    "    offload = test_cpu_offload()\n",
    "\n",
    "    # 提取最终显存使用量\n",
    "    print(f\"基础方法: {baseline['allocated'][-1]:.2f}GB\")\n",
    "    print(f\"ZeRO-1: {zero1['allocated'][-1]:.2f}GB ({(1-zero1['allocated'][-1]/baseline['allocated'][-1])*100:.1f}% 节省)\")\n",
    "    print(f\"ZeRO-2: {zero2['allocated'][-1]:.2f}GB ({(1-zero2['allocated'][-1]/baseline['allocated'][-1])*100:.1f}% 节省)\")\n",
    "    print(f\"ZeRO-3: {zero3['allocated'][-1]:.2f}GB ({(1-zero3['allocated'][-1]/baseline['allocated'][-1])*100:.1f}% 节省)\")\n",
    "    print(f\"CPU Offload: {offload['allocated'][-1]:.2f}GB ({(1-offload['allocated'][-1]/baseline['allocated'][-1])*100:.1f}% 节省)\")\n",
    "\n",
    "# 执行对比\n",
    "compare_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a33059",
   "metadata": {},
   "source": [
    "通过这个实验，我们可以清楚地看到 ZeRO 各级别对显存占用的优化效果。在实际的大模型训练中，这些优化可以带来数倍甚至数十倍的显存节省。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbd6f1",
   "metadata": {},
   "source": [
    "```\n",
    "显存使用对比 (单位: GB):\n",
    "----------------------------------------\n",
    "基础方法: 0.39GB\n",
    "ZeRO-1: 0.39GB (0.0% 节省)\n",
    "ZeRO-2: 0.31GB (20.5% 节省)\n",
    "ZeRO-3: 0.11GB (71.8% 节省)\n",
    "CPU Offload: 0.25GB (35.9% 节省)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308a22f1",
   "metadata": {},
   "source": [
    "## 总结与思考\n",
    "\n",
    "ZeRO 技术通过分片优化器状态、梯度和参数，显著降低了大模型训练的显存需求。本实验通过代码实现和原理分析，深入探讨了：\n",
    "\n",
    "1. **ZeRO-1**：优化器状态分片，减少约 4 倍显存占用\n",
    "2. **ZeRO-2**：梯度分片，进一步减少约 8 倍显存占用  \n",
    "3. **ZeRO-3**：参数分片，最大可减少约 N 倍显存占用（N 为 GPU 数量）\n",
    "4. **Zero Offload**：将数据卸载到 CPU/NVMe，支持训练超大模型\n",
    "\n",
    "这些技术可以组合使用，根据具体的硬件环境和模型大小选择最合适的配置。在实际应用中，DeepSpeed 框架提供了完整的 ZeRO 实现，建议直接使用经过优化的官方实现。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
