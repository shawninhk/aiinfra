<!--Copyright ¬© ZOMI ÈÄÇÁî®‰∫é[License](https://github.com/Infrasys-AI/AIInfra)ÁâàÊùÉËÆ∏ÂèØ-->

# PPÂπ∂Ë°åÔºö1F1B/1F1B Interleaved

abstractÔºöÂÖàÂâç‰ªãÁªçÁöÑ Gpipe Â≠òÂú®Á°¨‰ª∂Âà©Áî®Áéá‰ΩéÔºåÂä®ÊÄÅÂÜÖÂ≠òÂéãÂäõÂ§ßÁöÑÈóÆÈ¢òÔºåÊú¨ÁØá‰ªãÁªçÊñ∞ÁöÑÊµÅÊ∞¥Á∫øÊäÄÊúØÊù•ËßÑÈÅø

## PipeDream Âü∫Êú¨ÂéüÁêÜ

ÂõûÈ°æ‰∏Ä‰∏ã Gpipe ÊµÅÊ∞¥Âπ∂Ë°åÂ≠òÂú®Âä®ÊÄÅÂ≥∞ÂÄºÂÜÖÂ≠òÂ§ßÁöÑÈóÆÈ¢òÔºåÂ¶ÇÂõæÊâÄÁ§∫ÔºöËã•ËæìÂÖ• batch Ë¢´ÂàíÂàÜ‰∏∫ n ‰∏™ micro-batchÔºåÂàôÂØπ‰∫é‰ªªÊÑè deviceÔºåÈúÄË¶ÅÁºìÂ≠ò n ‰ªΩÂâçÂêëÊøÄÊ¥ªÂÄºÔºàÂõæ‰∏≠ n=8Ôºâ.

![Gpipeline ÂéüÁêÜ](images/10pipeline01.png)

PipeDream ÊµÅÊ∞¥Á∫øÂπ∂Ë°åÈááÂèñ‰∫Ü**1FIB**ÁöÑÁ≠ñÁï•ÔºåÂæàÂ•ΩÁöÑËßÑÈÅø‰∫ÜÁ°¨‰ª∂ÂÜÖÂ≠òÊúâÈôêÁöÑÈóÆÈ¢ò„ÄÇ

Âú®ÊµÅÊ∞¥Á∫øÂπ∂Ë°åÔºàpipeline parallelÔºâ‰∏≠ÔºåÊØèÊ¨°ÂâçÂêëËÆ°ÁÆó‰∫ßÁîüÁöÑ activation Âè™ÊúâÂú®ÂØπÂ∫îÁöÑÂèçÂêëËÆ°ÁÆóÂÆåÊàê‰πãÂêéÊâçËÉΩÈáäÊîæÔºàÂç≥‰Ωø‰ΩøÁî®‰∫Ü Checkpointing ÊäÄÊúØÔºâ„ÄÇÂõ†Ê≠§ÔºåË¶ÅÂ∞ΩÂèØËÉΩÂú∞ËäÇÁúÅ activation Âç†Áî®ÁöÑÊòæÂ≠òÔºåÂ∞±ÈúÄË¶ÅÂ∞ΩÈáèÁº©Áü≠ÊØè‰ªΩ activation Âú®ÂÜÖÂ≠ò‰∏≠ÂÅúÁïôÁöÑÊó∂Èó¥Ôºå‰πüÂ∞±ÊòØËÆ©ÂÆÉ‰ª¨Â∞ΩÊó©Ë¢´ÈáäÊîæ„ÄÇË¶ÅÂÅöÂà∞Ëøô‰∏ÄÁÇπÔºåÂÖ≥ÈîÆ‰æøÊòØËÆ©ÊØè micro-batch ÁöÑÂèçÂêëËÆ°ÁÆóÂ∞ΩÊó©ÂºÄÂßãÂπ∂ÂÆåÊàê„ÄÇ

ÂÖ∑‰ΩìÂÅöÊ≥ïÊòØÔºåÂ∞ÜÂèçÂêëËÆ°ÁÆóÁöÑ‰ºòÂÖàÁ∫ßË∞ÉÈ´òÔºå‰ΩøÂæóÁºñÂè∑ËæÉÂ∞èÁöÑ micro-batch ÁöÑÂèçÂêëÊ≠•È™§ÔºåËÉΩÂú®ÁºñÂè∑ËæÉÂ§ßÁöÑ micro-batch ÁöÑÂâçÂêëÊ≠•È™§‰πãÂâçÊâßË°å„ÄÇ‰ª•‰∏Ä‰∏™Â§öÈò∂ÊÆµÔºàstageÔºâÊµÅÊ∞¥Á∫ø‰∏∫‰æãÔºöÂ¶ÇÊûúÊàë‰ª¨ËÆ©ÊúÄÂêé‰∏Ä‰∏™ stage Âú®ÂÆåÊàêÂΩìÂâç micro-batch ÁöÑÂâçÂêëËÆ°ÁÆóÂêéÔºåÁ´ãÂàªÂêØÂä®ËØ• micro-batch ÁöÑÂèçÂêëËÆ°ÁÆóÔºåÈÇ£‰πàÂêéÁª≠ÁöÑÂêÑ‰∏™ stage Â∞±ËÉΩÊõ¥Êó©Âú∞Êî∂Âà∞ÂèçÂêëËÆ°ÁÆóÁöÑÊï∞ÊçÆÔºåËøõËÄåÂºÄÂßãÂÆÉ‰ª¨Ëá™Â∑±ÁöÑÂèçÂêëËÆ°ÁÆó„ÄÇ

ÈÄöËøá‚ÄúÂâçÂêëÂÅö‰∏ÄÊâπ„ÄÅÂèçÂêëÁ¥ßË∑ü‰∏ÄÊâπ‚ÄùÔºà1F1B one-forward-one-backwardÔºâÁöÑË∞ÉÂ∫¶Á≠ñÁï•Ôºå‰∏ç‰ªÖËÉΩÂ§üÂáèÂ∞ë activation Âú®ÊòæÂ≠ò‰∏≠ÁöÑÊªûÁïôÊó∂Èó¥ÔºåËøòËÉΩÂπ≥Ë°°ÂêÑ‰∏™ stage ÁöÑËÆ°ÁÆóË¥üËΩΩÔºåÊúÄÁªàÊúÄÂ§ßÂåñÊòæÂ≠òÂà©Áî®ÊïàÁéáÂπ∂Èôç‰ΩéÊï¥‰ΩìËÆ≠ÁªÉÊó∂ÁöÑÂÜÖÂ≠òÂ≥∞ÂÄºÈúÄÊ±Ç„ÄÇ

Âõ†Ê≠§Êàë‰ª¨ÂÆûÁé∞‰∫ÜÂ∞ÜÊøÄÊ¥ªÂÄºÊï∞Èáè‰∏äÈôê‰ªé micro-batch Êï∞Èáè **m** ÂèòÊàê pipeline stage Èò∂ÊÆµ **p**Ôºå‰ΩÜÂè™ÊòØÈôç‰Ωé‰∫ÜËÆæÂ§áÁöÑÂ≥∞ÂÄºÂÜÖÂ≠òÔºåÂπ∂Ê≤°ÊúâÈôç‰ΩéÊ∞îÊ≥°Â§ßÂ∞èÔºåÂõ†Ê≠§Á©∫Ê≥°Áéá‰∏é Gpipe ‰øùÊåÅ‰∏ÄËá¥Ôºö

$$
\begin{equation}
bubble ration=\frac{t_{bubble}}{t_{ideal}}=\frac{p-1}{m}
\end{equation}
$$

![PipeDream ÂéüÁêÜ](images/10pipeline02.png)

## Virtual pipeline Âü∫Êú¨ÂéüÁêÜ

ÂêéÁª≠ Megatron-LM Âú® 1F1B ÁöÑÂü∫Á°Ä‰∏äÂÅö‰∫Ü Interleaved 1F1B ÁöÑ‰ºòÂåñÔºåÂáèÂ∞ë‰∫ÜÊµÅÊ∞¥Á∫øÊ∞îÊ≥°Ôºå‰πüÂ∞±ÊòØÊú¨ÁØá‰ªãÁªçÁöÑËôöÊãüÊµÅÊ∞¥Âπ∂Ë°åÔºàVirtual Pipeline ParallelismÔºåÁÆÄÁß∞ VPPÔºâ„ÄÇ

VPP ÁöÑÊ†∏ÂøÉÂú®‰∫éÔºåËÆ©‰∏Ä‰∏™Áâ©ÁêÜÂ±ÇÈù¢ÁöÑ device ËôöÊãüÊàê‰∏∫ v ‰∏™ devicesÔºådevice ‰ªéËÆ°ÁÆó 1 ‰∏™ÊàñËøûÁª≠ layer ÊÆµÂà∞ËÆ°ÁÆó v ‰∏™‰∏çÁõ∏ÈÇªÁöÑ layerÔºåÂ¶ÇÂõæÊâÄÁ§∫ÔºöGPU1 ‰πãÂâçÂè™Ë¥üË¥£ layer1 Êàñ layer1+layer2 Â±ÇÁöÑËÆ°ÁÆóÔºåÁªèËøáËôöÊãüÂåñÊµÅÊ∞¥Á∫øÂêéÔºåË¥üË¥£ layer0 Âíå layer5 Â±ÇÁöÑËÆ°ÁÆóÔºå‰ΩøÂæó layer1 Â±ÇËÆ°ÁÆóÂÆåÊàêÂêéÊó†ÈúÄÁ≠âÂæÖ layer2 ÁöÑËÆ°ÁÆóÔºåÂèØ‰ª•Áõ¥Êé•ËøõÂÖ• GPU2 ËøõË°åËÆ°ÁÆóÔºå‰ªéËÄåÂáèÂ∞ëÁ≠âÂæÖÁ©∫Ê≥°Êó∂Èó¥ÔºåÊ≠§Â§Ñ v Ë¢´Áß∞‰∏∫ËôöÊãüÊµÅÊ∞¥Á∫øÈò∂ÊÆµÔºàvirtual pipeline stageÔºâ„ÄÇ

![ÂéüÁêÜ](images/10pipeline03.png)

ÂÅáËÆæÊ®°ÂûãÊÄªÂ±ÇÊï∞‰∏∫ 16ÔºåÂº†ÈáèÂπ∂Ë°åÂ§ßÂ∞è tp=1ÔºåÊµÅÊ∞¥Á∫øÂπ∂Ë°åÂ§ßÂ∞è pp=4ÔºåËôöÊãüÊµÅÊ∞¥Á∫øÂπ∂Ë°åÂ§ßÂ∞è v=2ÔºåÂàôÊ®°ÂûãÂ∞ÜË¢´ÂàíÂàÜ‰∏∫ 4 * 2 = 8 ‰∏™Èò∂ÊÆµÔºåÊØè‰∏™Èò∂ÊÆµÂåÖÂê´ 16 / 8 = 2 ‰∏™Â±Ç„ÄÇÂâçÂêëÁöÑÈ°∫Â∫è‰∏∫ GPU 1 -> GPU 2 -> GPU 3 -> GPU 4 -> GPU 1 -> GPU 2 -> GPU 3 -> GPU 4„ÄÇ

Âú®ËÆæÂ§áÊï∞Èáè‰∏çÂèòÁöÑÊÉÖÂÜµ‰∏ãÔºåÂàÜÂá∫Êõ¥Â§öÁöÑÊµÅÊ∞¥Á∫øÈò∂ÊÆµÔºåËøôÊ†∑ÂèØ‰ª•ËÆ©ÊµÅÊ∞¥Á∫ø‰∏≠ÊØè‰∏™ stage Êõ¥Â∞èÔºåÂõ†ËÄå‰∏ã‰∏™ stage ÁöÑÁ≠âÂæÖÊó∂Èó¥Êõ¥Áü≠ÔºåÊ∞îÊ≥°Êõ¥Â∞è„ÄÇÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåm ÈúÄË¶ÅÊòØ p ÁöÑÊï¥Êï∞ÂÄç„ÄÇ

![VirtualPP ÂéüÁêÜ](images/10pipeline04.png)

ùëö ‰∏∫ micro-batchÔºåùëù‰∏∫ pipeline stagesÔºåv ‰∏∫ virtual pipeline stage,ÂÆåÊàê v ‰∏™ layer ÊÆµ‰∏≠‰∏Ä‰∏™ÁöÑÂâçÂêë„ÄÅÂêéÂêëÊó∂Èó¥ÂàÜÂà´‰∏∫ $t_f/v$ Âíå $t_b/v$,ÊµÅÊ∞¥Á∫øÊ∞îÊ≥°ÁöÑËÄóÊó∂ $t_{pd}^{int}$:

$$
\begin{equation}
t_{pd}^{int}=\frac{(p-1)*(t_f+t_b)}{v}
\end{equation}
$$

Âõ†Ê≠§ÂèØÂæóÂá∫ VPP ÁöÑÁ©∫Ê≥°ÁéáÔºö

$$
\begin{equation}
bubble ration=\frac{1}{v}*\frac{p-1}{m}
\end{equation}
$$

Á©∫Ê≥°ÁéáÈô§‰∫ÜË∑ü micro batch ÊàêÂèçÊØîÔºå‰∏é v ‰πüÊàêÂèçÊØî„ÄÇ

ÈúÄË¶ÅÊ≥®ÊÑèÁöÑÊòØÔºåVPP ÊòØ‰ª•Â¢ûÂä†ÈÄö‰ø°Èáè‰∏∫‰ª£‰ª∑ÔºåÊç¢ÂèñÊõ¥‰ΩéÁöÑÁ©∫Ê≥°ÊØîÁéáÔºåÁõ∏ÊØî‰∫é 1FB Áé∞Âú®ÁöÑÊ∞îÊ≥°Âç†ÊØîÂ∞±ÂáèÂ∞ëÂà∞‰∫Ü 1/v„ÄÇ‰ΩÜÊòØÊµÅÊ∞¥Á∫ø‰πãÈó¥ÁöÑÈÄö‰ø°Èáè‰πüÂ¢ûÂä†‰∫Ü v ÂÄç„ÄÇÂØπ‰∫é‰∏Ä‰∏™ pipeline stageÔºåÈáåÈù¢ÂåÖÊã¨Â§ö‰∏™ Transformer layerÔºåÊâÄ‰ª•Áé∞Âú®Áõ∏ÂΩì‰∫éÊµÅÊ∞¥Á∫øÁöÑ stage Â¢ûÂä†‰∫ÜÔºåÈÄö‰ø°Èáè‰πü‰ºöÂ¢ûÂä†„ÄÇÁâπÂà´ÊòØÂΩì global ÁöÑ batch Ë∂äÊù•Ë∂äÂ§ßÁöÑÊó∂ÂÄôÔºåËøô‰∏™ÈÄö‰ø°ÂºÄÈîÄÂ∞±‰ºöÊõ¥ÊòæËëó„ÄÇ

## Êñ∞ÂÖ¥ PP ÊäÄÊúØÔºàÊâ©ÂÖÖÔºâ

### PipeDream-2BW

PipeDream-2BW ÊòØ‰∏ÄÁßçÈù¢ÂêëË∂ÖÂ§ßËßÑÊ®°Ê∑±Â∫¶Ê®°ÂûãÁöÑÂºÇÊ≠•ÊµÅÊ∞¥Á∫øÂπ∂Ë°åÊñπÊ≥ïÔºöÂÆÉÂ∞ÜÊ®°ÂûãÂàáÂàÜ‰∏∫Â§ö‰∏™Èò∂ÊÆµÂπ∂Â§çÂà∂Â§öË∑ØÊµÅÊ∞¥Á∫øÔºåÂú® 1F1B Ë∞ÉÂ∫¶‰∏ãÈÄöËøá‚ÄúÂèåÁºìÂÜ≤‚ÄùÊùÉÈáçÊõ¥Êñ∞ÂíåÊ¢ØÂ∫¶ÂêàÂπ∂ÊäÄÊúØÔºåÂ§ßÂπÖÈôç‰ΩéÊòæÂ≠òÂç†Áî®‰∏éÈÄö‰ø°ÂºÄÈîÄÔºõÂÜÖÁΩÆÁöÑËá™Âä®Âåñ Planner Ê†πÊçÆËÆæÂ§áÂÜÖÂ≠òÂíå‰∫íËÅîÊãìÊâëÊêúÁ¥¢ÊúÄ‰ºòÈò∂ÊÆµÂàíÂàÜ‰∏éÂ§çÂà∂ÂÆΩÂ∫¶ÔºåÂπ∂ÂèØÈÄâÊøÄÊ¥ªÈáçËÆ°ÁÆóÔºõÂú®Â§öÂç°ÈõÜÁæ§‰∏äËÆ≠ÁªÉÂ§ßËßÑÊ®° Transformer Ê®°ÂûãÊó∂ÔºåÁõ∏ËæÉ‰∫é‰º†ÁªüÊµÅÊ∞¥Á∫øÂπ∂Ë°åÔºåÂêûÂêêÈáèÂèØÊèêÂçáÊï∞ÂÄçÔºåÂêåÊó∂‰øùÁïô‰∏éÊï∞ÊçÆÂπ∂Ë°å‰∏ÄËá¥ÁöÑÊùÉÈáçÊõ¥Êñ∞ËØ≠‰πâ„ÄÇ

![PipeDream-2BW ÂéüÁêÜ](images/10pipeline05.png)

### ZB-V schedule

ZB-V schedule ÊòØ‰∏ÄÁßçÈù¢ÂêëÊµÅÊ∞¥Á∫øÂπ∂Ë°åÁöÑÂÜÖÂ≠òÈ´òÊïàÈõ∂Ê∞îÊ≥°Ë∞ÉÂ∫¶Á≠ñÁï•ÔºöÂÆÉÂ∞Ü p ‰∏™Èò∂ÊÆµÂàíÂàÜ‰∏∫ 2p ‰∏™Ê®°ÂûãÂùóÔºåÂπ∂ÁªôÊØè‰∏™ worker ÂàÜÈÖç‰∏§‰∏™Ê®°ÂûãÂùóÔºåÊåâÁÖß‰ªéÈ¶ñÂà∞Â∞æÂÜçËøîÂõûÈ¶ñÁöÑ V ÂûãÈ°∫Â∫èËøõË°åÂàÜÈÖçÔºå‰ª•Á°Æ‰øùÊØè‰∏™ÂæÆÊâπÊ¨°ÁöÑÂâçÂêëÂíåÂØπÊùÉÈáçÁöÑÂêéÂêëÈÉΩÂú®Âêå‰∏Ä worker ‰∏äÊâßË°åÔºå‰ªéËÄåÂà©Áî®ÂêéÂêëÊùÉÈáçËÆ°ÁÆóÂ°´ÂÖÖÊµÅÊ∞¥Á∫øÁ©∫ÈöôÔºõÂú®‰∏é 1F1B Áõ∏ÂêåÁöÑÊòæÂ≠òÁ∫¶Êùü‰∏ãÔºåÂèØÂú®Ê≠£Âêë„ÄÅÂêéÂêëËæìÂÖ•‰∏éÊùÉÈáçÂêéÂêëËÆ°ÁÆóÊó∂Èó¥Áõ∏Á≠âÊó∂ÂÆûÁé∞ËøëÈõ∂Ê∞îÊ≥°ÔºõÂêåÊó∂ÔºåËØ•Ë∞ÉÂ∫¶‰øùÊåÅÂêÑ worker Â≥∞ÂÄºÊøÄÊ¥ªÂÜÖÂ≠òÂùáË°°ÔºåÂÖºÈ°æÂêûÂêê‰∏éÊòæÂ≠òÊïàÁéá„ÄÇ

![ZB-V schedule ÂéüÁêÜ](images/10pipeline06.png)

### Hanayo wave-like pipeline

Hanayo ÊòØ‰∏ÄÁßçÊ≥¢Êµ™ÂºèÊµÅÊ∞¥Á∫øÂπ∂Ë°åÁ≠ñÁï•ÔºöÂÆÉÂ∞ÜÊ®°ÂûãÂàíÂàÜ‰∏∫ S ‰∏™Èò∂ÊÆµÂπ∂Â∞ÜÂ∞èÊâπÊ¨°ÂàÜÊàê W ‰∏™Ê≥¢ÔºàwaveÔºâÔºå‰ª•Ê≥¢Êµ™ÂΩ¢ÁöÑÈ°∫Â∫èÂú®ÂêÑÈò∂ÊÆµ‰∫§ÈîôÊâßË°åÂâçÂêëÂíåÂêéÂêëËÆ°ÁÆóÔºåËÉΩÂ§üÂ∞ÜÊµÅÊ∞¥Á∫øÊ∞îÊ≥°ÊØî‰æãÈôç‰ΩéËá≥ÂéüÊù•ÁöÑ 1/(2W) ‰∏îÊó†ÈúÄÂ§çÂà∂Ê®°ÂûãÔºå‰ªéËÄå‰øùÊåÅ‰∏é‰∏ªÊµÅÊñπÊ≥ï‰∏ÄËá¥ÁöÑÊùÉÈáçÂíåÊøÄÊ¥ªÂÜÖÂ≠òÂç†Áî®ÔºõÂêåÊó∂ÔºåÂÖ∂ËΩªÈáèÁ∫ßËøêË°åÊó∂ÂºïÊìéÂ∞ÜË∞ÉÂ∫¶ÈÄªËæë‰∏éÊâßË°åÂíåÈÄö‰ø°‰ºòÂåñËß£ËÄ¶ÔºåÊîØÊåÅÂú®Â§öÂç°ÈõÜÁæ§‰∏äÁÅµÊ¥ªÈÉ®ÁΩ≤ÔºõÂú®ÂØπ GPT Âíå BERT Á±ªÊ®°Âûã„ÄÅÊúÄÂ§ö 32 Âùó GPU ÁöÑÊµãËØï‰∏≠ÔºåHanayo Áõ∏ËæÉÊúÄÂÖàËøõÊñπÊ°àÂÆûÁé∞‰∫ÜÊúÄÈ´ò 30.4%ÁöÑÂêûÂêêÈáèÊèêÂçá

![Hanayo wave-like ÂéüÁêÜ](images/10pipeline07.png)

## ÂàÜÂ∏ÉÂºèÊ°ÜÊû∂ÈáåÁöÑ PP ÂÆûÁé∞

- Ê®°ÂûãËøêË°åÂÖ•Âè£‰∏é PP ÈÖçÁΩÆÔºö

pretrain_gpt.py main ÂáΩÊï∞Ë∞ÉÁî® pretrain->get_model,get_model ÂáΩÊï∞Âà§Êñ≠ pipeline ÁöÑÂàíÂàÜÁ≠ñÁï•
```

Megatron-LM/pretrain_gpt.py

if __name__ == "__main__":

    # Temporary for transition to core datasets
    train_valid_test_datasets_provider.is_distributed = True

    # Optionally enable inprocess restart on pretrain
    pretrain, store = inprocess_restart.maybe_wrap_for_inprocess_restart(pretrain)

    pretrain(
        train_valid_test_datasets_provider,
        model_provider,
        ModelType.encoder_or_decoder,
        forward_step,
        args_defaults={'tokenizer_type': 'GPT2BPETokenizer'},
        extra_args_provider=add_modelopt_args if has_nvidia_modelopt else None,
        store=store,
    )
```

pretrain ÂáΩÊï∞ÂÜÖÈÉ®Ë∞ÉÁî® setup_model_and_optimizer ÂáΩÊï∞ÔºåËØ•ÂáΩÊï∞ÂÜÖÈÉ®Ë∞ÉÁî® get_model

```
Megatron-LM/megatron/training/training.py/def pretrain

# Model, optimizer, and learning rate.
timers('model-and-optimizer-setup', log_level=0).start(barrier=True)
app_metrics['app_build_optimizer_start_time'] = one_logger_utils.get_timestamp_in_ms()
model, optimizer, opt_param_scheduler = setup_model_and_optimizer(
    model_provider, model_type, checkpointing_context=checkpointing_context
)

Megatron-LM/megatron/training/training.py/def setup_model_and_optimizer

def setup_model_and_optimizer(
    model_provider_func,
    model_type,
    no_wd_decay_cond=None,
    scale_lr_cond=None,
    lr_mult=1.0,
    checkpointing_context=None,
):
    """Setup model and optimizer."""
    args = get_args()
    timers = get_timers()
    one_logger = get_one_logger()

    model = get_model(model_provider_func, model_type)
    unwrapped_model = unwrap_model(model)
```

get_model ÈÄöËøá get_args ÂáΩÊï∞ÊãøÂà∞ÂêØÂä®ËÑöÊú¨ËÆæÁΩÆÁöÑË∂ÖÂèÇÔºåÂèÇÊï∞ËÆæÁΩÆÂ¶ÇÂõæÊâÄÁ§∫Ôºö

![args Ë∂ÖÂèÇËÆæÁΩÆ](images/10pipeline08.png)

```
Megatron-LM/megatron/training/training.py/def get_model

def get_model(model_provider_func, model_type=ModelType.encoder_or_decoder, wrap_with_ddp=True):
    """Build the model."""
    args = get_args()
    args.model_type = model_type

    # Build model.
```

Ê≠§Â§ÑÂàÜ‰∏∫‰∏§ÁßçÊÉÖÂÜµËÆ®ËÆ∫Ôºå‰ª•‰∏ãÊòØÂêØÁî®ËôöÊãüÁÆ°ÈÅì(VPP)ÁöÑÊ®°ÂûãÊûÑÂª∫ÔºåÂà§Êñ≠Êù°‰ª∂Â¶ÇÁ¨¨‰∏Ä‰∏™ if ÊâÄÁ§∫„ÄÇÂà§ÂÆöÈÄªËæëÊ†áËÆ∞‰∫ÜÔºöÂè™ÊúâÁ¨¨‰∏Ä‰∏™ rank ÂÅöËæìÂÖ•ÔºåÊúÄÂêé‰∏Ä‰∏™ rank ÂÅöËæìÂá∫ÔºåÂà©Áî® model_provider_func ÂáΩÊï∞ËÆ°ÁÆóÂΩìÂâç Rank ËØ•‚ÄúÂàá‚ÄùÂì™‰∏ÄÊÆµ Transformer Â±ÇÂπ∂ÂÆû‰æãÂåñÔºåÊúÄÁªàÊääÊâÄÊúâ Rank ÊåâÈ°∫Â∫èÊîæÂÖ• model ÂàóË°®Ôºå‰æõÂêéÈù¢ÁöÑÊµÅÊ∞¥Á∫øË∞ÉÂ∫¶Âô®Âæ™ÁéØË∞ÉÁî®„ÄÇ

```
Megatron-LM/megatron/training/training.py/def get_model
 
  if (
            mpu.get_pipeline_model_parallel_world_size() > 1
            and args.virtual_pipeline_model_parallel_size is not None
        ):
            if model_type == ModelType.encoder_and_decoder:
                assert (
                    args.encoder_pipeline_model_parallel_size == 0
                ), "Interleaved schedule not supported for model with encoder on separate PP rank"
            model = []
            for i in range(args.virtual_pipeline_model_parallel_size):
                # Set pre_process and post_process only after virtual rank is set.
                pre_process = mpu.is_pipeline_first_stage(ignore_virtual=False, vp_stage=i)
                post_process = mpu.is_pipeline_last_stage(ignore_virtual=False, vp_stage=i)
                this_model = model_provider_func(
                    pre_process=pre_process, post_process=post_process, vp_stage=i)
                this_model.model_type = model_type
                this_model.vp_stage = i
                model.append(this_model)
```

Âê¶ÂàôÂêØÁî® PipeDream ÊµÅÊ∞¥Á∫øÂπ∂Ë°åÔºåÊ†πÊçÆÊ®°ÂûãÁ±ªÂûãÂíåÂπ∂Ë°åÂ∫¶ÔºåÂ∞ÜÁºñÁ†ÅÂô®ÂíåËß£Á†ÅÂô®Ê®°ÂùóÂêàÁêÜÂú∞ÊãÜÂàÜÂà∞‰∏çÂêå GPUÔºå‰øùËØÅÂâçÂêë/ÂèçÂêë‰º†ÈÄíÁöÑÊ≠£Á°ÆÊÄß‰∏éÈ´òÊïàÊÄß„ÄÇ

```
Megatron-LM/megatron/training/training.py/def get_model

else:
            pre_process = mpu.is_pipeline_first_stage()
            post_process = mpu.is_pipeline_last_stage()
            add_encoder = True
            add_decoder = True
            if model_type == ModelType.encoder_and_decoder:
                if mpu.get_pipeline_model_parallel_world_size() > 1:
                    rank = mpu.get_pipeline_model_parallel_rank()
                    first_decoder_rank = args.encoder_pipeline_model_parallel_size
                    world_size = mpu.get_pipeline_model_parallel_world_size()
                    pre_process = rank == 0 or rank == first_decoder_rank
                    post_process = (rank == (first_decoder_rank - 1)) or (rank == (world_size - 1))
                    add_encoder = mpu.is_inside_encoder(rank)
                    add_decoder = mpu.is_inside_decoder(rank)
                model = model_provider_func(
                    pre_process=pre_process,
                    post_process=post_process,
                    add_encoder=add_encoder,
                    add_decoder=add_decoder,
                )
            else:
                model = model_provider_func(pre_process=pre_process, post_process=post_process)
            model.model_type = model_type
        return model
```

- PP Ê®°ÂûãÂÆû‰æãÂåñÔºöÔºàÊ≤°ÊâæÂÖ®Ôºâ

ÈÄöËøá‰∏äËø∞ get_model ÂáΩÊï∞ÈáåÁöÑ model_provider_func ÂáΩÊï∞ÊûÑÂª∫Ê®°ÂûãÂÆû‰æãÔºåmodel_provider_func Âπ∂‰∏çÊòØ Megatron-Core Â∫ìÈáå‰∏Ä‰∏™ÂçïÁã¨ÁöÑÂÖ®Â±ÄÂáΩÊï∞ÔºåËÄåÊòØÁî±ÂêÑ‰∏™È¢ÑËÆ≠ÁªÉËÑöÊú¨(Â¶Ç pretrain_gpt.py)ÂÆö‰πâÂπ∂‰º†ÂÖ•Ê†∏ÂøÉËÆ≠ÁªÉÊµÅÁ®ãÁöÑÂõûË∞É„ÄÇ

```
Megatron-LM/pretrain_gpt.py

def model_provider(
    pre_process=True, post_process=True, vp_stage: Optional[int] = None
) -> Union[GPTModel, megatron.legacy.model.GPTModel]:
```

ÊûÑÂª∫ GPTModel ÂÆû‰æãÔºå

```
Megatron-LM/megatron/core/models/gpt/gpt_model.py

class GPTModel(LanguageModule):
    def __init__(...):

        # Transformer.
        self.decoder = TransformerBlock(
            config=self.config,
            spec=transformer_layer_spec,
            pre_process=self.pre_process,
            post_process=self.post_process,
            vp_stage=vp_stage,
        )
```

- PP Ëé∑ÂèñÈúÄË¶ÅÊâßË°åÁöÑÂ±ÇÊï∞ÔºöÔºàÊ≤°ÁúãÊáÇÔºâ

TransformerBlock Ê≥®ÂÜåÈÄöËøá get_num_layers_to_build ËÆ°ÁÆóÂΩìÂâç Stage ÂåÖÂê´Âá†‰∏™ Transformer Layer
```
Megatron-LM/megatron/core/transformer/transformer_block.py

def get_num_layers_to_build(config: TransformerConfig, vp_stage: Optional[int] = None) -> int:
    return num_layers_to_build

class TransformerBlockSubmodules:

    def _get_block_submodules(...):

    if isinstance(spec, TransformerBlockSubmodules):
            return spec

        # ModuleSpec here is generally assumed to be for a transformer layer that
        # is implemented in `transformer_layer.py` or if it subclasses
        # `BaseTransformerLayer` from the `transformer_layer.py` file.
        elif isinstance(spec, ModuleSpec):
            if issubclass(spec.module, TransformerBlock):
                return spec.submodules
            elif issubclass(spec.module, BaseTransformerLayer):
                num_layers = get_num_layers_to_build(config, vp_stage)
                return TransformerBlockSubmodules(
                    layer_specs=[spec] * num_layers, layer_norm=LayerNormImpl
                )
            else:
                raise Exception(f"specialize for {spec.module.__name__}.")
        else:
            raise Exception(f"specialize for {type(spec).__name__}.")
```

Âú® GPT Ê®°ÂûãËøêË°åÁ§∫‰æã‰∏≠ÊØè‰∏™ Stage build_layer ÁöÑ‰∏™Êï∞‰∏∫ number_lyaer = L / PP_num

```
Megatron-LM/megatron/core/transformer/transformer_block.py

class TransformerBlock(MegatronModule):
    """Transformer class."""

    def __init__Ôºà
        self.num_layers_per_pipeline_rank = len(self.layers)

    def _build_layers(self):
        # Transformer layers.
        # @jcasper can we improve how we deal with layer_number?
        # currently it's only used in CoreAttention?
        # if self.apply_query_key_layer_scaling:
        #     coeff = self.layer_number
        #     self.norm_factor *= coeff
        def build_layer(layer_spec, layer_number):
            global_layer_number = layer_number + get_transformer_layer_offset(
                self.config, self.vp_stage
            )  # 1-based index
            if self.config.heterogeneous_block_specs:
                layer_config = self.config.get_config_for_layer(global_layer_number)
            else:
                layer_config = self.config
```

- ÊâßË°å PP ËÆ≠ÁªÉÔºö

GPT ËÆ≠ÁªÉË∞ÉÁî® pretrain -> train -> train_stepÔºåÊâßË°å‰∏Ä‰∏™ iteration, train_step ÂáΩÊï∞ÈÄöËøá get_forward_backward_fun()ÂáΩÊï∞ËøõÂÖ• schedulers.py Ê®°ÂùóÔºåÂπ∂Ê†πÊçÆÂΩìÂâçÁöÑ PP Ê®°ÂºèËøîÂõû forward_backward_pipelining_with_interleaving ÊâßË°åÂâçÂêëÂíåÂèçÂêëËÆ°ÁÆó

```
Megatron-LM/megatron/training/training.py

def train_step(forward_step_func, data_iterator, model, optimizer, opt_param_scheduler, config):
    """Single training step."""
            ...
    # Forward pass.
        forward_backward_func = get_forward_backward_func()
        losses_reduced = forward_backward_func(
            forward_step_func=forward_step_func,
            data_iterator=data_iterator,
            model=model,
            num_microbatches=get_num_microbatches(),
            seq_length=args.seq_length,
            micro_batch_size=args.micro_batch_size,
            decoder_seq_length=args.decoder_seq_length,
            forward_only=False,
            adjust_tensor_shapes_fn=adjust_tensor_shapes_fn,
        )


Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def get_forward_backward_func():
    pipeline_model_parallel_size = parallel_state.get_pipeline_model_parallel_world_size()
    if pipeline_model_parallel_size > 1:
        if parallel_state.get_virtual_pipeline_model_parallel_world_size() is not None:
            forward_backward_func = forward_backward_pipelining_with_interleaving
        else:
            forward_backward_func = forward_backward_pipelining_without_interleaving
    else:
        forward_backward_func = forward_backward_no_pipelining
    return forward_backward_func
```

- NPU0 ÊâßË°å stage0Ôºà‰∏çÊ∏ÖÊô∞Ôºâ

ÊâßË°å Forward ËÆ°ÁÆóÔºåÈÄâÊã© forward_backward_pipelining_without_interleaving Ê®°Âºè
(‰ª• Pipeline 1F1B ‰∏∫‰æãÔºåÂç≥ PipeDream) ÂÖàÂÖ≥Èó≠Ê¢ØÂ∫¶Êõ¥Êñ∞ÔºåÁ≠âÊâÄÊúâÁöÑ microbatch ÊâßË°åÂÆåÊØïÊâçÊõ¥Êñ∞Ê¢ØÂ∫¶„ÄÇËøáÁ®ãÂ¶ÇÂõæÊâÄÁ§∫Ôºö

![args Ë∂ÖÂèÇËÆæÁΩÆ](images/10pipeline10.png)

ÈÉ®ÂàÜ‰ª£Á†ÅÂ±ïÁ§∫Ôºö

ÂÖ∂‰∏≠Ôºönum_microbatchesÔºöÊÄªÁöÑ micro batch ‰∏™Êï∞„ÄÇnum_warmup_microbatchesÔºöÂΩìÂâç rank warmup Èò∂ÊÆµÈúÄË¶ÅËÆ°ÁÆóÔºåÁõ¥Âà∞ 1F1B ÁöÑ microbatch ÁöÑ‰∏™Êï∞„ÄÇ

num_microbatches_remainingÔºöÂΩìÂâç rank ËøòÂâ©‰∏ãÂ§öÂ∞ë‰∏™ microbatch ÊâßË°åÊâçÂà∞ 1F1B Èò∂ÊÆµÔºåÂç≥ num_microbatches - num_warmup_microbatches„ÄÇ

```
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_backward_pipelining_without_interleaving(
    ...
    micro_batch_size: int,
    ...
):
    ...
    disable_grad_sync()

    # Compute number of warmup microbatches.
    num_warmup_microbatches = (
        parallel_state.get_pipeline_model_parallel_world_size()
        - parallel_state.get_pipeline_model_parallel_rank()
        - 1
    )
    num_warmup_microbatches = min(num_warmup_microbatches, num_microbatches)
    num_microbatches_remaining = num_microbatches - num_warmup_microbatches
```

- NPU0 ÂÆåÊàêÂâçÂêëËÆ°ÁÆóÔºåÂ¶ÇÂõæÊâÄÁ§∫Ôºö

NPU0 Âú® stage0 Èò∂ÊÆµÊ≤°ÊúâÂÖ∂ÂÆÉÁöÑ Stage ÊøÄÊ¥ªËæìÂÖ•ÔºåÂõ†Ê≠§ÂøΩÁï• recv_forward()ÂáΩÊï∞Ôºåforward_step Ë∞ÉÁî® forward_step_func ÁúüÊ≠£Ë∞ÉÁî®Ê®°ÂûãÊâßË°åÔºö
![NPU0 ÂÆåÊàê FI](images/10pipeline12.png)

```python
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

 # Run warmup forward passes.
    for i in range(num_warmup_microbatches):
        # Decide to checkpoint all layers' activations of the current micro-batch
        if max_outstanding_backprops is not None:
            checkpoint_activations_microbatch = (
                i % max_outstanding_backprops
                >= config.num_microbatches_with_partial_activation_checkpoints
            )
        else:
            checkpoint_activations_microbatch = None

        input_tensor = recv_forward(
            recv_tensor_shapes, config, parallel_state.is_pipeline_first_stage()
        )
        output_tensor, num_tokens = forward_step(
            forward_step_func,
            data_iterator,
            model,
            num_microbatches,
            input_tensor,
            forward_data_store,
            config,
            collect_non_loss_data,
            checkpoint_activations_microbatch,
            check_first_val_step(first_val_step, forward_only, i == 0),
            current_microbatch=i,
            encoder_decoder_xattn=encoder_decoder_xattn,
        )

        def forward_step(...)
            ...
            if config.enable_autocast:
                context_manager = torch.autocast("cuda", dtype=config.autocast_dtype)
            else:
                context_manager = contextlib.nullcontext()
            with context_manager:
                if checkpoint_activations_microbatch is None:
                    output_tensor, loss_func = forward_step_func(data_iterator, model)
                else:
                    output_tensor, loss_func = forward_step_func(
                        data_iterator, model, checkpoint_activations_microbatch
                    )
```

- NPU0 ÂâçÂêë‰º†ÈÄíÊøÄÊ¥ªÔºåÂ¶ÇÂõæÊâÄÁ§∫Ôºö

![NPU0 ‰º†ÈÄíÊøÄÊ¥ª](images/10pipeline13.png)

NPU0 ‰∏äËæìÂá∫ Stage0 output_tensor Âêé send_forward ÂèëÈÄÅÁªô‰∏ã‰∏Ä‰∏™ StageÔºåÈÄöËøá P2P_communication.send_forward ÂèëÈÄÅ output_tensorÔºåÈÄöËøá torch.distributed.P2POp ÂºÇÊ≠• send output_tensorÔºåÊúÄÂêéË∞ÉÁî® torch.cuda.synchronize() ÊâßË°åÂêåÊ≠•

```python
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

        send_forward(
            output_tensor, send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
        )

        def send_forward(output_tensors, tensor_shapes, config, is_last_stage):
    """Wrapper for p2p_communication.send_forward used with non-interleaving schedule."""
    if not isinstance(output_tensors, list):
        output_tensors = [output_tensors]
    for output_tensor, tensor_shape in zip(output_tensors, tensor_shapes):
        if tensor_shape is None:
            continue
        p2p_communication.send_forward(output_tensor, config, is_last_stage)

Megatron-LM/megatron/core/pipeline_parallel/p2p_communication.py

      if wait_on_reqs and len(reqs) > 0:
        for req in reqs if isinstance(reqs, list) else reqs.values():
            req.wait()
        reqs = None

    if (
        (config.batch_p2p_comm and config.batch_p2p_sync)
        # The lists below have a size > 1 only when ETP ‚â† DTP,
        # meaning this synchronization is required when ETP ‚â† DTP.
        or len(tensor_recv_prev_list) > 1
        or len(tensor_recv_next_list) > 1
    ):
        # To protect against race condition when using batch_isend_irecv().
        # User should assert that we have a modern enough PyTorch to not need this
        torch.cuda.synchronize()    
```

- NPU0 ÁªßÁª≠ËÆ°ÁÆóÔºö

NPU0 ÁªßÁª≠ÊâßË°å forward_step,Stage0 ÂâçÂêëËÆ°ÁÆóÂæóÂà∞Á¨¨‰∫å‰∏™ output_tensor,Âà©Áî® sedn_forward_recv_backward ÂáΩÊï∞ÂèëÈÄÅ output_tensor Á≠âÂæÖ backwardÔºåËøõÂÖ• 1F1B Áä∂ÊÄÅÔºåÈÄöËøá send_backward_recv_backward Â∫ïÂ±ÇËØï‰∏ãÈÄöËøá P2PPp ÂºÇÊ≠•Ôºåsend output_tesnorÔºå‰∏îÂºÇÊ≠• recv tensor_recv_nextÔºåÊúÄÂêéË∞ÉÁî® synchronize()Á≠âÂæÖ recv backwardÔºåNPU0 ËøõÂÖ•Á≠âÂæÖÁä∂ÊÄÅ„ÄÇ

![NPU0 ËÆ°ÁÆó F2](images/10pipeline17.png)

```python
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_backward_pipelining_without_interleaving(...):
 def enable_grad_sync():
    # Run warmup forward passes.
    for i in range(num_warmup_microbatches):
        # Decide to checkpoint all layers' activations of the current micro-batch
        if max_outstanding_backprops is not None:
            checkpoint_activations_microbatch = (
                i % max_outstanding_backprops
                >= config.num_microbatches_with_partial_activation_checkpoints
            )
        else:
            checkpoint_activations_microbatch = None

        input_tensor = recv_forward(
            recv_tensor_shapes, config, parallel_state.is_pipeline_first_stage()
        )
        output_tensor, num_tokens = forward_step(
            forward_step_func,
            data_iterator,
            model,
            num_microbatches,
            input_tensor,
            forward_data_store,
            config,
            collect_non_loss_data,
            checkpoint_activations_microbatch,
            check_first_val_step(first_val_step, forward_only, i == 0),
            current_microbatch=i,
            encoder_decoder_xattn=encoder_decoder_xattn,
        )
```

- NPU1 ËøõË°åÂâçÂêëËÆ°ÁÆóÔºö

ÂÖ∂ËøáÁ®ãÂêå GPU0 ‰∏ÄËá¥ÔºåÂ¶ÇÂõæÊâÄÁ§∫Ôºö

num_warmup_microbatches=0ÔºåËøõÂÖ• 1F1B Áä∂ÊÄÅÔºånum_microbatches_remaining=3Ôºårecv_forward Ë∞ÉÁî® P2POp ÂºÇÊ≠• recvÔºåNPU1 ÊúÄÂêéË∞ÉÁî® synchronize() ÊâßË°åÂêåÊ≠•Á≠âÂæÖ NPU0 Stage0 ËæìÂá∫Ôºå‰ªéËÄå‰øùËØÅ NPU0 to NPU1 ÁöÑÊâßË°åÈ°∫Â∫è„ÄÇ

![NPU1 ËÆ°ÁÆó](images/10pipeline14.png)

NPU1 recv_forward Á≠âÂæÖ NPU0 Stage0 ÂèëÈÄÅ intput_tensor Âêé NPU1 forward_step ËÆæÁΩÆ iNPUt_tensorÔºåÂÆûÁé∞ NPU0&NPU1 ‰∫§Êç¢ËæìÂÖ•ËæìÂá∫ NPU1 ËøõÂÖ• 1F1B Âæ™ÁéØÔºåforward_step_func Ë∞ÉÁî® GPTModel ÊâßË°åÂâçÂêëËÆ°ÁÆó„ÄÇNPU1 ‰∏ä TransformerBlock ÊâßË°åÁ¨¨‰∏Ä‰∏™ StageÔºåPre_process=FalseÔºåÂç≥‰∏ç‰ºöÊää iNPUt_embeddings ‰Ωú‰∏∫ ransformer ÁöÑËæìÂÖ•Ôºå‰ΩøÁî® NPU0 Stage0 ËæìÂÖ•ÁöÑ iNPUt_tensor ‰Ωú‰∏∫ËæìÂÖ•ÊâßË°åÂæóÂà∞ output tensor„ÄÇ

![NPU1 ËÆ°ÁÆó](images/10pipeline15.png)

```python
Megatron-LM/megatron/core/transformer/transformer_block.py

class TransformerBlock(MegatronModule):
    """Transformer class."""

    def __init__(
        self,
        config: TransformerConfig,
        spec: Union[TransformerBlockSubmodules, ModuleSpec],
        post_layer_norm: bool = True,
        pre_process: bool = False,
        post_process: bool = True,
        model_comm_pgs: ModelCommProcessGroups = None,
        vp_stage: Optional[int] = None,
    ):
        super().__init__(config=config)

        self.submodules = _get_block_submodules(config, spec, vp_stage)
        self.post_layer_norm = post_layer_norm
        self.pre_process = pre_process
        self.post_process = post_process
        self.vp_stage = vp_stage

    def forward(...):
        if not self.pre_process:
            # See set_input_tensor()
            hidden_states = self.input_tensor
```

Á§∫‰æã‰∏≠ NPU1 Stage1 ÊòØÊúÄÂêé‰∏ÄÂ±Ç StaegeÔºåÂõ†Ê≠§ post_process=True,ÊâßË°å is_pipeline_last_stage ËÆ°ÁÆó GPT Ê®°ÂûãÁöÑ output_tensor Âíå loss„ÄÇ

![NPU1 ËÆ°ÁÆó](images/10pipeline16.png)

```python
Megatron-LM/megatron/core/transformer/transformer_block.py

class TransformerBlock(MegatronModule):
    """Transformer class."""

    def __init__(
        self,
        config: TransformerConfig,
        spec: Union[TransformerBlockSubmodules, ModuleSpec],
        post_layer_norm: bool = True,
        pre_process: bool = True,
        post_process: bool = True,
        model_comm_pgs: ModelCommProcessGroups = None,
        vp_stage: Optional[int] = None,
    ):

Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_step(...)
    ...
   if parallel_state.is_pipeline_last_stage(ignore_virtual=False, vp_stage=vp_stage):
        if not collect_non_loss_data:
            outputs = loss_func(output_tensor)
            if len(outputs) == 3:
                output_tensor, num_tokens, loss_reduced = outputs
                if not config.calculate_per_token_loss:
                    output_tensor /= num_tokens
                    output_tensor /= num_microbatches
            else:
                # preserve legacy loss averaging behavior (ie, over the number of microbatches)
                assert len(outputs) == 2
                output_tensor, loss_reduced = outputs
                output_tensor *= parallel_state.get_context_parallel_world_size()
                output_tensor /= num_microbatches
            forward_data_store.append(loss_reduced)
        else:
            data = loss_func(output_tensor, non_loss_data=True)
            forward_data_store.append(data)
```

- NPU1 ÂèçÂêëÊâßË°å Stage1Ôºö

ÊâßË°åÂÆå forward_step ÂêéÊâßË°å backward_step ÂæóÂà∞ iNPUt_tensor_gradÔºåÂπ∂
ËøõÂÖ• 1F1B Áä∂ÊÄÅÔºåÊâßË°å send_backward_recc_forward->_communication->ÂºÇÊ≠•ÂèëÈÄÅ iNPUt_tensor_grad Áªô NPU0 Âπ∂Á≠âÂæÖ NPU0 ÂèëÈÄÅ‰∏ã‰∏Ä‰∏™ MB forward ÁªìÊûú„ÄÇ

![NPU1 ÂèçÂêëËÆ°ÁÆó](images/10pipeline18.png)

```python
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def forward_backward_pipelining_without_interleaving(...):
    # Enable grad sync for the last microbatch in the batch if the full
    # backward pass completes in the 1F1B stage.
    if num_warmup_microbatches == 0 and last_iteration:
        if config.grad_sync_func is None or rank == 0:
            enable_grad_sync()

    input_tensor_grad = backward_step(
        input_tensor, output_tensor, output_tensor_grad, model_type, config
    )

    if last_iteration:
        input_tensor = None
        send_backward(
            input_tensor_grad,
            recv_tensor_shapes,
            config,
            parallel_state.is_pipeline_first_stage(),
        )
    else:
        input_tensor = send_backward_recv_forward(
            input_tensor_grad,
            recv_tensor_shapes,
            config,
            parallel_state.is_pipeline_first_stage(),
        ) 

def send_backward_recv_forward(input_tensor_grads, tensor_shapes, config, is_first_stage):
    """Wrapper for p2p_communication.send_backward_recv_forward used
    with non-interleaving schedule."""
    if not isinstance(input_tensor_grads, list):
        input_tensor_grads = [input_tensor_grads]
    input_tensors = []
    for input_tensor_grad, tensor_shape in zip(input_tensor_grads, tensor_shapes):
        if tensor_shape is None:
            input_tensors.append(None)
            continue
        input_tensor = p2p_communication.send_backward_recv_forward(
            input_tensor_grad, tensor_shape, config, is_first_stage
        )
        input_tensors.append(input_tensor)
    return input_tensors
```

- NPU0 ÂèçÂêëÊâßË°å Stage0Ôºö

NPU0 Srage0 Á≠âÂæÖ send_backward_recv_forward Ë¢´Âî§ÈÜíÂêéËé∑Âæó NPU1 Staege1 ÂèëÈÄÅÁöÑ output_tensor_gradÔºåNPU0 Stage0 ÊâßË°å backward_step ËæìÂá∫ intput_tensor_gradÔºåNPU0 ËÆ°ÂÖ• 1F1B Áä∂ÊÄÅÔºåNPU0 num_warmup_mbs=1, num_mbs_remaining=2ÔºåËøõÂÖ• 1F1B Âæ™ÁéØÔºåÊâßË°å forward_step ÊâßË°å Starge1 ÂâçÂêëËÆ°ÁÆóÂæóÂà∞ output_tensor(Forward 3)ÔºåÊâßË°å send_forward_recv_backward ÂèëÈÄÅ output_tensor Á≠âÂæÖ backwardÔºåÂºÇÊ≠• recv tensor_recv_nextÔºåË∞ÉÁî® synnchronize()ÂêåÊ≠•Á≠âÂæÖ backwardÔºåNPU0 ËøõÂÖ•Á≠âÂæÖÁä∂ÊÄÅ„ÄÇ

![NPU0 ÂèçÂêë‰º†Ëæì](images/10pipeline19.png)

```python
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

 # Run 1F1B in steady state.
    for i in range(num_microbatches_remaining):
        last_iteration = i == (num_microbatches_remaining - 1)

        # Decide to checkpoint all layers' activations of the current micro-batch
        if max_outstanding_backprops is not None:
            checkpoint_activations_microbatch = (
                (i + num_warmup_microbatches) % max_outstanding_backprops
            ) >= config.num_microbatches_with_partial_activation_checkpoints
        else:
            checkpoint_activations_microbatch = None

        output_tensor, num_tokens = forward_step(...)
        total_num_tokens += num_tokens

        if forward_only:
            send_forward(
                output_tensor, send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
            )

            if not last_iteration:
                input_tensor = recv_forward(
                    recv_tensor_shapes, config, parallel_state.is_pipeline_first_stage()
                )

        else:
            output_tensor_grad = send_forward_recv_backward(
                output_tensor, send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
            )


Megatron-LM/megatron/core/pipeline_parallel/p2p_communication.py

  if recv_prev:
        if config.pipeline_dtype is None:
            raise RuntimeError("pipeline_dtype must be provided if recv_prev is True")
        if tensor_shape is None:
            raise RuntimeError(
                "tensor_shape must be specified if recv_prev is True. "
                "Common tensor_shape is (seq_length, micro_batch_size, hidden_size)"
            )
        tensor_recv_prev_func = create_tensor_recv_prev

    if recv_next:
        if config.pipeline_dtype is None:
            raise RuntimeError("dtype must be provided if recv_next is True")
        if tensor_shape is None:
            raise RuntimeError(
                "tensor_shape must be specified if recv_next is True. "
                "Common tensor_shape is (seq_length, micro_batch_size, hidden_size)"
            )
        tensor_recv_next_func = create_tensor_recv_next
```

- NPU1 ÂèçÂêëÊâßË°å Stage1Ôºö

ÂêåÁêÜÔºåNPU1 Stage1 ‰∏äÊâßË°å send_backward_recv_forward ÂêåÊ≠•Á≠âÂæÖÊî∂Âà∞ NPU0
Stge0 ÂèëÈÄÅ iNPUt_tensorÔºàForward 2Ôºâ,NPU1 Stage1 Â∞Ü iNPUt_tensorÔºàForward 2Ôºâ‰Ωú‰∏∫ TransformerBlock ÊâßË°å forward_step,ÂæóÂà∞ËæìÂá∫ output_tensor„ÄÇ
![NPU1 ÂèçÂêë‰º†Ëæì](images/10pipeline19.png)

- NPU0 ÊâßË°å Stage0

NPU0 Á≠âÂæÖ send_forward_recv_backward ÊâßË°å NPU1 ËæìÂá∫ output_grad(B2)ÔºåÊâßË°å backward_step ËæìÂá∫ iNPUt_tensor_gradÔºàB2ÔºâÔºåNPU0 num_warmup_mbs=1, num_mbs_remaing=2, i=2ÔºåÈÄÄÂá∫ 1F1BÔºåËøõÂÖ• cooldown backwrd pass enable_grad_sync ÊâìÂºÄÊ®°ÂûãÊ¢ØÂ∫¶Êõ¥Êñ∞Ôºårecv_backward Á≠âÂæÖ NPU1 ÂèëÈÄÅÊúÄÂêé‰∏Ä‰∏™ mbs ÁöÑ backwardÔºàB3ÔºâÔºåNPU0 ÂáÜÂ§áÊõ¥Êñ∞Ê®°ÂûãÁöÑÊ¢ØÂ∫¶ÂíåÂèÇÊï∞„ÄÇ

![NPU1 ÂèçÂêë‰º†Ëæì](images/10pipeline20.png)

- NPU1 ÊâßË°å Stage1

NPU1 Stage1 ÊâßË°å send_backward_recv_forward ÂêåÊ≠•Á≠âÂæÖ iNPUt(F3),NPU1 num_warmup_mbs=0Ôºånum_mbs_remaining=3ÔºåËøõÂÖ• 1F1B Âæ™ÁéØ,Â∞Ü NPU0 Stage0 ÂèëÈÄÅ iNPUt(F3)‰Ωú‰∏∫ TransformerBlock ÁöÑ iNPUt ËÆ°ÁÆóÂâçÂêë,forward_step()ËæìÂá∫ output (F3)ÊâßË°å backward_step()ÂæóÂà∞ iNPUt_tensor_grad(B3),send_backward()ÂºÇÊ≠•ÂèëÈÄÅ iNPUt_tesnor_grad(B3)Áªô NPU0„ÄÇ

![NPU1 ÂèçÂêë‰º†Ëæì](images/10pipeline21.png)

- NPU0 ÊâßË°å Stage0 ÂêéÔºåÊâßË°åÂÆåÂÆåÊï¥ÁöÑ iteration

NPU0 Á≠âÂæÖ cooldown backward ÁöÑ recv_backward()Ëé∑Âæó NPU1 ËæìÂá∫(B3)ÔºåÊâßË°å backward_step()ËæìÂá∫ iNPUt_tensor_grad(B3)Ôºåforward_backward_func()ËøîÂõû LOSSÔºåenable_grad_sync()Á¥ØÂä†Êõ¥Êñ∞Ê®°ÂûãÊ¢ØÂ∫¶Ôºåfinalize_model_grads_func()Êõ¥Êñ∞Ê®°ÂûãÂèÇÊï∞„ÄÇ

![NPU1 ÂèçÂêë‰º†Ëæì](images/10pipeline22.png)

```python
Megatron-LM/megatron/core/pipeline_parallel/schedules.py

def get_forward_backward_func():
  pipeline_model_parallel_size = parallel_state.get_pipeline_model_parallel_world_size()
    if pipeline_model_parallel_size > 1:
        if parallel_state.get_virtual_pipeline_model_parallel_world_size() is not None:
            forward_backward_func = forward_backward_pipelining_with_interleaving
        else:
            forward_backward_func = forward_backward_pipelining_without_interleaving
    else:
        forward_backward_func = forward_backward_no_pipelining
    return forward_backward_func


def forward_backward_pipelining_without_interleaving(...)
    def enable_grad_sync():
        output_tensor_grad = recv_backward(
                        send_tensor_shapes, config, parallel_state.is_pipeline_last_stage()
                    )

                    input_tensor_grad = backward_step(
                        input_tensor, output_tensor, output_tensor_grad, model_type, config
                    )

                    send_backward(
                        input_tensor_grad,
                        recv_tensor_shapes,
                        config,
                        parallel_state.is_pipeline_first_stage(),
                    )

                # Launch any remaining grad reductions.
                if no_sync_context is not None:
                    enable_grad_sync()
                    if config.grad_sync_func is not None:
                        config.grad_sync_func(model.parameters())

            if config.finalize_model_grads_func is not None and not forward_only:

                # If defer_embedding_wgrad_compute is enabled we need to do the
                # weight gradient GEMM's here.
                finish_embedding_wgrad_compute(config, embedding_module)

                # Finalize model grads (perform full grad all-reduce / reduce-scatter for
                # data parallelism, layernorm all-reduce for sequence parallelism, and
                # embedding all-reduce for pipeline parallelism).
                config.finalize_model_grads_func(
                    [model], total_num_tokens if config.calculate_per_token_loss else None
                )

            if config.timers is not None:
                config.timers('forward-backward').stop()

            if hasattr(config, 'enable_cuda_graph') and config.enable_cuda_graph:
                create_cudagraphs()

            return forward_data_store
```
## ÊÄªÁªì‰∏éÊÄùËÄÉ


## ÂèÇËÄÉÊñáÁåÆ

- https://zhuanlan.zhihu.com/p/650744349
- https://zhuanlan.zhihu.com/p/701716465
- https://blog.csdn.net/just_sort/article/details/135981391
- https://blog.csdn.net/HaoBBNuanMM/article/details/134095326
- https://github.com/NVIDIA/Megatron-LM